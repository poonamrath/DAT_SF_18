{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: working with a smaller subset of Prudential data \n",
    "\n",
    "The point is to be able to go through with a workflow on my laptop. \n",
    "\n",
    "Data set (59381 rows) is randomly subsetted to a smaller df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and magic here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read input dataset\n",
    "input_csv = './train.csv'\n",
    "df_raw = pd.read_csv(input_csv, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Randomly extract 500 rows from df_raw into df_sampled **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample df_raw to create a smaller, easier to work with df\n",
    "rows = np.random.choice(df_raw.index.values,500)\n",
    "df_sampled = df_raw.ix[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 127)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identify predictor variables and response varibales, and create corresponding DFs\n",
    "\n",
    "def split_response_from_features(df):\n",
    "    response = 'Response'\n",
    "    all_predictors = [col for col in df.columns if col not in response]\n",
    "    df_predictors = df[all_predictors]\n",
    "    df_response = df[response]\n",
    "    df_response_with_dummies = pd.get_dummies(df_response,prefix='Response')\n",
    "    return df_predictors, df_response, df_response_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predictors = split_response_from_features(df_sampled)[0]\n",
    "df_response_with_dummies = split_response_from_features(df_sampled)[2]\n",
    "df_response = split_response_from_features(df_sampled)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Product_Info_1', u'Product_Info_2', u'Product_Info_3',\n",
       "       u'Product_Info_4', u'Product_Info_5', u'Product_Info_6',\n",
       "       u'Product_Info_7', u'Ins_Age', u'Ht', u'Wt', \n",
       "       ...\n",
       "       u'Medical_Keyword_40', u'Medical_Keyword_41', u'Medical_Keyword_42',\n",
       "       u'Medical_Keyword_43', u'Medical_Keyword_44', u'Medical_Keyword_45',\n",
       "       u'Medical_Keyword_46', u'Medical_Keyword_47', u'Medical_Keyword_48',\n",
       "       u'Response'],\n",
       "      dtype='object', length=127)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary exploratory plots:**\n",
    "1. Wt versus BMI (Intuitively one would guess there is a positive correlation).\n",
    "2. Plot the distribution of Resposne variable to see if there are evenly represented in df_sample. If not we might need to upsample, downsample or generate rows for the underrepresented response by SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEkCAYAAAChew9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQHK3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f552682f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot scatterplot of Wt vs BMI\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.scatter(df_sampled.BMI,df_sampled.Wt,s=40)\n",
    "    # add axis label\n",
    "    plt.xlabel('BMI')\n",
    "    plt.ylabel('Wt')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f55267c6b90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAESCAYAAADpO/4pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyyjYRURc5v8DI3FuaDRDFvcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5526737310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of Response\n",
    "sns.distplot(df_sampled.Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Response#8 : 159\n",
      "Total number of Response#2 : 64\n",
      "Total number of Response#7 : 74\n",
      "Total number of Response#6 : 98\n",
      "Total number of Response#1 : 42\n",
      "Total number of Response#5 : 37\n",
      "Total number of Response#4 : 22\n",
      "Total number of Response#3 : 4\n",
      "{1: 42, 2: 64, 3: 4, 4: 22, 5: 37, 6: 98, 7: 74, 8: 159}\n"
     ]
    }
   ],
   "source": [
    "response_count = {}\n",
    "for ii in df_sampled.Response.unique():\n",
    "    response_count[ii] = len(df_sampled[df_sampled.Response==ii])\n",
    "    total_num = len(df_sampled[df_sampled.Response==ii])\n",
    "    print \"Total number of Response#{} : {}\".format(ii,total_num)\n",
    "print response_count       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on the Response column\n",
    "1. Response 6,8 is roughly 4-5 times higher than the rest of the responses : consider undersampling.\n",
    "2. Response 3 and 4 are way less than the others: consider oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Describe each feature: Number of uniques, number of nulls, type_of_feature, distribution\n",
    "\n",
    "def get_dummy_features(df, verbose=False, dummy_threshold = 200):\n",
    "    features_for_dummification = []\n",
    "    num_rows = len(df)\n",
    "\n",
    "    for each_feature in df.columns:\n",
    "        num_uniques = len(df[each_feature].unique())\n",
    "        num_nulls = df[each_feature].isnull().sum()\n",
    "        example = df[each_feature].iloc[0]\n",
    "        \n",
    "        # Keep track of dummy features\n",
    "        if isinstance(example, str) or (num_uniques*dummy_threshold<num_rows and isinstance(example, (int, long))): \n",
    "            features_for_dummification.append(each_feature)\n",
    "\n",
    "        if verbose==True:\n",
    "            print '{}: Uniques: {}/{}. Nulls: {}. Type: {}'.format(each_feature, num_uniques, \n",
    "                                                               num_rows, num_nulls, type_of_feature)\n",
    "            \n",
    "            \n",
    "    return features_for_dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "# check if number of dummiable columns in the original df and the sampled df are the same\n",
    "print len(get_dummy_features(df_raw,verbose=False,dummy_threshold=200))\n",
    "print len(get_dummy_features(df_sampled,verbose=False,dummy_threshold=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product_Info_1',\n",
       " 'Product_Info_2',\n",
       " 'Product_Info_5',\n",
       " 'Product_Info_6',\n",
       " 'Product_Info_7',\n",
       " 'Employment_Info_3',\n",
       " 'Employment_Info_5',\n",
       " 'InsuredInfo_2',\n",
       " 'InsuredInfo_4',\n",
       " 'InsuredInfo_5',\n",
       " 'InsuredInfo_6',\n",
       " 'InsuredInfo_7',\n",
       " 'Insurance_History_1',\n",
       " 'Insurance_History_2',\n",
       " 'Insurance_History_3',\n",
       " 'Family_Hist_1',\n",
       " 'Medical_History_3',\n",
       " 'Medical_History_4',\n",
       " 'Medical_History_5',\n",
       " 'Medical_History_6',\n",
       " 'Medical_History_9',\n",
       " 'Medical_History_11',\n",
       " 'Medical_History_12',\n",
       " 'Medical_History_13',\n",
       " 'Medical_History_16',\n",
       " 'Medical_History_17',\n",
       " 'Medical_History_19',\n",
       " 'Medical_History_20',\n",
       " 'Medical_History_21',\n",
       " 'Medical_History_22',\n",
       " 'Medical_History_23',\n",
       " 'Medical_History_26',\n",
       " 'Medical_History_27',\n",
       " 'Medical_History_28',\n",
       " 'Medical_History_29',\n",
       " 'Medical_History_30',\n",
       " 'Medical_History_31',\n",
       " 'Medical_History_33',\n",
       " 'Medical_History_34',\n",
       " 'Medical_History_35',\n",
       " 'Medical_History_37',\n",
       " 'Medical_History_38',\n",
       " 'Medical_History_39',\n",
       " 'Medical_History_40',\n",
       " 'Medical_History_41',\n",
       " 'Medical_Keyword_1',\n",
       " 'Medical_Keyword_2',\n",
       " 'Medical_Keyword_3',\n",
       " 'Medical_Keyword_4',\n",
       " 'Medical_Keyword_5',\n",
       " 'Medical_Keyword_6',\n",
       " 'Medical_Keyword_7',\n",
       " 'Medical_Keyword_8',\n",
       " 'Medical_Keyword_9',\n",
       " 'Medical_Keyword_10',\n",
       " 'Medical_Keyword_11',\n",
       " 'Medical_Keyword_12',\n",
       " 'Medical_Keyword_13',\n",
       " 'Medical_Keyword_14',\n",
       " 'Medical_Keyword_15',\n",
       " 'Medical_Keyword_16',\n",
       " 'Medical_Keyword_17',\n",
       " 'Medical_Keyword_18',\n",
       " 'Medical_Keyword_19',\n",
       " 'Medical_Keyword_20',\n",
       " 'Medical_Keyword_21',\n",
       " 'Medical_Keyword_22',\n",
       " 'Medical_Keyword_23',\n",
       " 'Medical_Keyword_24',\n",
       " 'Medical_Keyword_25',\n",
       " 'Medical_Keyword_26',\n",
       " 'Medical_Keyword_27',\n",
       " 'Medical_Keyword_28',\n",
       " 'Medical_Keyword_29',\n",
       " 'Medical_Keyword_30',\n",
       " 'Medical_Keyword_31',\n",
       " 'Medical_Keyword_32',\n",
       " 'Medical_Keyword_33',\n",
       " 'Medical_Keyword_34',\n",
       " 'Medical_Keyword_35',\n",
       " 'Medical_Keyword_36',\n",
       " 'Medical_Keyword_37',\n",
       " 'Medical_Keyword_38',\n",
       " 'Medical_Keyword_39',\n",
       " 'Medical_Keyword_40',\n",
       " 'Medical_Keyword_41',\n",
       " 'Medical_Keyword_42',\n",
       " 'Medical_Keyword_43',\n",
       " 'Medical_Keyword_44',\n",
       " 'Medical_Keyword_45',\n",
       " 'Medical_Keyword_46',\n",
       " 'Medical_Keyword_47',\n",
       " 'Medical_Keyword_48']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dummy_features(df_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The answer is no: 108 for original df_raw and 94 for df_sampled. But that's ok. Just go ahead with the workflow anyway.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn chosen features into dummy variables\n",
    "def create_dummy_features(df, features_for_dummification, verbose=True):\n",
    "    df_expanded = df\n",
    "\n",
    "    for each_feature in features_for_dummification:\n",
    "        if verbose==True:\n",
    "            print \"Expanding variable: {}\".format(each_feature)\n",
    "        df_temp = pd.get_dummies(df[each_feature], prefix=each_feature)\n",
    "        df_expanded = pd.concat([df_expanded, df_temp], axis = 1, join = 'inner')\n",
    "        df_expanded.drop(each_feature,inplace=True, axis=1)\n",
    "        \n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20265, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Since training data and test data have different distributions for \"dummyizable\" features, it makes sense to\n",
    "# # build out dummy features using a combined distribution\n",
    "df_oos_sneak_peek = pd.read_csv('./test.csv', index_col = 0)\n",
    "df_predictors_enhanced = pd.concat([df_predictors, df_oos_sneak_peek], axis = 0, join = 'outer')\n",
    "df_predictors_enhanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Employment_Info_3', 'Employment_Info_5', 'Family_Hist_1', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'InsuredInfo_2', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', 'InsuredInfo_7', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_16', 'Medical_History_17', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_3', 'Medical_History_30', 'Medical_History_31', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_4', 'Medical_History_40', 'Medical_History_41', 'Medical_History_5', 'Medical_History_6', 'Medical_History_9', 'Product_Info_1', 'Product_Info_2', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7']\n"
     ]
    }
   ],
   "source": [
    "# Since Medical_Keyword is already dummied, make sure you exclude it in the dummying process!\n",
    "features_for_dummification = get_dummy_features(df_predictors)\n",
    "features_already_dummy = ['Medical_Keyword_{}'.format(num) for num in range(1,49)]\n",
    "features_for_dummification = sorted(list(set(features_for_dummification) - set(features_already_dummy)))\n",
    "print features_for_dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding variable: Employment_Info_3\n",
      "Expanding variable: Employment_Info_5\n",
      "Expanding variable: Family_Hist_1\n",
      "Expanding variable: Insurance_History_1\n",
      "Expanding variable: Insurance_History_2\n",
      "Expanding variable: Insurance_History_3\n",
      "Expanding variable: InsuredInfo_2\n",
      "Expanding variable: InsuredInfo_4\n",
      "Expanding variable: InsuredInfo_5\n",
      "Expanding variable: InsuredInfo_6\n",
      "Expanding variable: InsuredInfo_7\n",
      "Expanding variable: Medical_History_11\n",
      "Expanding variable: Medical_History_12\n",
      "Expanding variable: Medical_History_13\n",
      "Expanding variable: Medical_History_16\n",
      "Expanding variable: Medical_History_17\n",
      "Expanding variable: Medical_History_19\n",
      "Expanding variable: Medical_History_20\n",
      "Expanding variable: Medical_History_21\n",
      "Expanding variable: Medical_History_22\n",
      "Expanding variable: Medical_History_23\n",
      "Expanding variable: Medical_History_26\n",
      "Expanding variable: Medical_History_27\n",
      "Expanding variable: Medical_History_28\n",
      "Expanding variable: Medical_History_29\n",
      "Expanding variable: Medical_History_3\n",
      "Expanding variable: Medical_History_30\n",
      "Expanding variable: Medical_History_31\n",
      "Expanding variable: Medical_History_33\n",
      "Expanding variable: Medical_History_34\n",
      "Expanding variable: Medical_History_35\n",
      "Expanding variable: Medical_History_37\n",
      "Expanding variable: Medical_History_38\n",
      "Expanding variable: Medical_History_39\n",
      "Expanding variable: Medical_History_4\n",
      "Expanding variable: Medical_History_40\n",
      "Expanding variable: Medical_History_41\n",
      "Expanding variable: Medical_History_5\n",
      "Expanding variable: Medical_History_6\n",
      "Expanding variable: Medical_History_9\n",
      "Expanding variable: Product_Info_1\n",
      "Expanding variable: Product_Info_2\n",
      "Expanding variable: Product_Info_5\n",
      "Expanding variable: Product_Info_6\n",
      "Expanding variable: Product_Info_7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 205)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the functions from above (df_expanded has dummy variables)\n",
    "df_sample_expanded_enhanced = create_dummy_features(df_predictors_enhanced,features_for_dummification)\n",
    "df_expanded = df_sample_expanded_enhanced.drop(df_oos_sneak_peek.index)\n",
    "df_expanded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question about performing correlations: should we test this before making dummies?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Compute pairwise correlations of all predictors\n",
    "# df_predictors = df_expanded\n",
    "# df_predictor_correlations = df_predictors.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Describe pairwise correlations\n",
    "# _corr_threshold = 0.5\n",
    "\n",
    "# for pred in all_predictors:\n",
    "#     df_temp = df_predictor_correlations[pred]\n",
    "#     max_corr = df_temp[[idx for idx in df_temp.index if pred not in idx]].max()\n",
    "#     min_corr = df_temp.min()\n",
    "#     if np.isnan(max_corr)==False:\n",
    "#         if abs(min_corr)>max_corr:\n",
    "#             other_pred = df_temp[df_temp==min_corr].index[0]\n",
    "#             mcorr = min_corr\n",
    "#         else:\n",
    "#             other_pred = df_temp[df_temp==max_corr].index[0]\n",
    "#             mcorr = max_corr\n",
    "#         if abs(mcorr)>_corr_threshold:\n",
    "#             print '** ',\n",
    "#         print 'mcorr({})={:.4f} with {}'.format(pred, mcorr, other_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "1. Fill NAs for both the predictord and response with median estimates of the column (not localized approach as of now)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:2602: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response_1</th>\n",
       "      <th>Response_2</th>\n",
       "      <th>Response_3</th>\n",
       "      <th>Response_4</th>\n",
       "      <th>Response_5</th>\n",
       "      <th>Response_6</th>\n",
       "      <th>Response_7</th>\n",
       "      <th>Response_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73476</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31055</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66064</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59409</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26352</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19740</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39873</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71299</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18651</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73631</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50627</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34120</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56361</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33968</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Response_1  Response_2  Response_3  Response_4  Response_5  Response_6  \\\n",
       "Id                                                                              \n",
       "9836            0           0           0           0           0           0   \n",
       "9121            0           1           0           0           0           0   \n",
       "3396            0           0           0           0           0           0   \n",
       "73476           0           1           0           0           0           0   \n",
       "57135           0           0           0           0           0           1   \n",
       "31055           1           0           0           0           0           0   \n",
       "66064           0           0           0           0           1           0   \n",
       "29641           0           0           0           0           0           0   \n",
       "32616           0           0           0           0           0           1   \n",
       "17921           0           0           0           0           0           0   \n",
       "11880           0           0           0           0           0           1   \n",
       "9042            0           0           0           0           0           1   \n",
       "3913            0           0           0           1           0           0   \n",
       "21016           0           0           0           0           0           0   \n",
       "59409           1           0           0           0           0           0   \n",
       "26352           0           0           0           0           0           0   \n",
       "56464           0           0           0           0           0           0   \n",
       "73641           0           0           0           0           0           1   \n",
       "19740           0           0           0           0           0           1   \n",
       "43182           1           0           0           0           0           0   \n",
       "41160           0           0           0           0           0           0   \n",
       "5513            0           0           0           0           0           0   \n",
       "39873           0           1           0           0           0           0   \n",
       "71299           0           0           0           0           0           1   \n",
       "40473           0           0           0           0           0           1   \n",
       "44699           0           0           0           0           0           1   \n",
       "18651           0           0           0           0           0           0   \n",
       "61644           0           0           0           1           0           0   \n",
       "57155           0           0           0           0           0           0   \n",
       "73631           0           0           0           0           0           1   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "70996           0           0           0           0           0           0   \n",
       "5370            0           0           0           0           0           0   \n",
       "50627           0           0           0           0           0           1   \n",
       "52137           0           0           0           0           0           0   \n",
       "24829           0           0           0           0           0           0   \n",
       "19753           0           0           0           0           1           0   \n",
       "67051           0           0           0           0           0           0   \n",
       "14182           0           1           0           0           0           0   \n",
       "40460           0           0           0           0           0           0   \n",
       "4932            0           0           0           0           0           1   \n",
       "57912           0           0           0           0           0           0   \n",
       "20233           0           0           0           0           0           1   \n",
       "16465           0           0           0           0           0           0   \n",
       "58868           0           0           0           0           0           0   \n",
       "37824           0           0           0           1           0           0   \n",
       "2908            0           0           0           0           0           0   \n",
       "34120           1           0           0           0           0           0   \n",
       "36131           0           0           0           0           0           1   \n",
       "56361           0           0           0           0           1           0   \n",
       "47206           0           0           0           0           0           0   \n",
       "58098           0           0           0           0           0           1   \n",
       "45867           0           0           0           0           0           1   \n",
       "33968           0           1           0           0           0           0   \n",
       "42953           0           0           0           0           0           0   \n",
       "5937            0           0           0           0           0           0   \n",
       "57288           0           1           0           0           0           0   \n",
       "76486           0           0           0           0           1           0   \n",
       "1247            0           0           0           0           0           0   \n",
       "58396           0           0           0           0           0           0   \n",
       "7226            0           0           0           0           0           1   \n",
       "\n",
       "       Response_7  Response_8  \n",
       "Id                             \n",
       "9836            0           1  \n",
       "9121            0           0  \n",
       "3396            1           0  \n",
       "73476           0           0  \n",
       "57135           0           0  \n",
       "31055           0           0  \n",
       "66064           0           0  \n",
       "29641           1           0  \n",
       "32616           0           0  \n",
       "17921           0           1  \n",
       "11880           0           0  \n",
       "9042            0           0  \n",
       "3913            0           0  \n",
       "21016           0           1  \n",
       "59409           0           0  \n",
       "26352           0           1  \n",
       "56464           1           0  \n",
       "73641           0           0  \n",
       "19740           0           0  \n",
       "43182           0           0  \n",
       "41160           0           1  \n",
       "5513            1           0  \n",
       "39873           0           0  \n",
       "71299           0           0  \n",
       "40473           0           0  \n",
       "44699           0           0  \n",
       "18651           1           0  \n",
       "61644           0           0  \n",
       "57155           0           1  \n",
       "73631           0           0  \n",
       "...           ...         ...  \n",
       "70996           0           1  \n",
       "5370            0           1  \n",
       "50627           0           0  \n",
       "52137           0           1  \n",
       "24829           1           0  \n",
       "19753           0           0  \n",
       "67051           0           1  \n",
       "14182           0           0  \n",
       "40460           1           0  \n",
       "4932            0           0  \n",
       "57912           1           0  \n",
       "20233           0           0  \n",
       "16465           1           0  \n",
       "58868           0           1  \n",
       "37824           0           0  \n",
       "2908            0           1  \n",
       "34120           0           0  \n",
       "36131           0           0  \n",
       "56361           0           0  \n",
       "47206           0           1  \n",
       "58098           0           0  \n",
       "45867           0           0  \n",
       "33968           0           0  \n",
       "42953           0           1  \n",
       "5937            0           1  \n",
       "57288           0           0  \n",
       "76486           0           0  \n",
       "1247            0           1  \n",
       "58396           1           0  \n",
       "7226            0           0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NAs with median estimates\n",
    "df_predictors_selected = df_expanded\n",
    "df_response_selected = df_response_with_dummies\n",
    "\n",
    "df_predictors_selected.fillna(df_predictors_selected.median(),inplace=True)\n",
    "df_response_selected.fillna(df_response_selected.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on Response variable:**\n",
    "    \n",
    "When I use all 8 dummy columns for response, I get \"bad shape\" error below. I will try using just one Response columns(1 through 8) \n",
    "and try OnevsRest or some method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_response.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve\n",
    "\n",
    "The point is to see if we have enough data. We will do this by determining cross-validated training and test scores for different training set sizes. I'm going to give this a shot with Logistic Regression using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, ShuffleSplit \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign predictors to X and response to Y\n",
    "X = df_predictors_selected\n",
    "#y = df_response_selected\n",
    "y = df_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 205)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfqUQMDBWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1095d3a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "title = \"Learning curve Logistic Regression\"\n",
    "#cv = cross_validation.ShuffleSplit(digits.data.shape[0], n_iter=100,test_size=0.2, random_state=0)\n",
    "cv=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=1)\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building:\n",
    "\n",
    "**Make another version of the data where the minority response values are oversampled OR synthetically generated using SMOTE. First use the original dataset and then the altered for each model:[X,y OR X1,y1]**\n",
    "\n",
    "1. Fit independent models using all features:\n",
    "    1.1 Logistic Regression\n",
    "    1.2 Naive Bayes\n",
    "    1.3 K-Nearest Neighbor\n",
    "\n",
    "\n",
    "\n",
    "2. Plot learning curve for any (?) model that gives a decent accuracy to see if we have enough data in hand!!\n",
    "\n",
    "\n",
    "\n",
    "3. Fit ensemble models using all features:\n",
    "    3.1 RandomForest\n",
    "    3.2 Gradient Boosting Classifier\n",
    "    3.3 Voting Classifier (combo of models from Step#1: show that base classifiers are better than a coin toss)\n",
    "    \n",
    " \n",
    "**Other points to think about:**\n",
    "\n",
    "1) K-fold cross-validation can be folded into the model: each run will give a score: we can get the median score.\n",
    "\n",
    "\n",
    "2) Feature selection: We should apply penalty (C which is 1/lambda.. C=0.1 means high penalty. Apply Lasso). Find coefficients and discuss the importance. Look for intuitive explanations. \n",
    "2.1) For Logistic Regression and Naive Bayes, we will get probabilities so besides just looking at the median CV score,w ill it be useful to look at the confusion matrix, find TPR, FPR, plot a ROC curve and determine AUC? Is that of interest to Prudential??\n",
    "\n",
    "\n",
    "3) To simplify the model, if scores aren't awesome, we can even remove features showing multicollinearity by the correlation rule in the book. (Should we be looking at covariance?). Will PCA help in finding out which features are colinear? Because they will be on the same axis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-fold cross-validation score: 0.340048967051\n",
      "3-fold cross-validation score: 0.321212121212\n",
      "4-fold cross-validation score: 0.333289256198\n",
      "5-fold cross-validation score: 0.323529411765\n",
      "6-fold cross-validation score: 0.349668774466\n",
      "7-fold cross-validation score: 0.347826086957\n",
      "8-fold cross-validation score: 0.336021505376\n",
      "9-fold cross-validation score: 0.333333333333\n",
      "10-fold cross-validation score: 0.343289689034\n",
      "\n",
      "Best CV score: 0.349668774466\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAElCAYAAACbLIdpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ef60710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit LOGISTIC REGRESSION model and compute the max cross_validation score over various K-folds.\n",
    "model_lr = LogisticRegression(penalty = 'l1',C=0.05) # Instantiate Logistic Regression model\n",
    "scores =[]\n",
    "jj = 0\n",
    "for ii in range(2,11):\n",
    "    scores.append(np.median(cross_val_score(model_lr, X, y, cv=StratifiedKFold(y, ii, shuffle=False))))\n",
    "    print \"{}-fold cross-validation score: {}\".format(ii,scores[jj])\n",
    "    jj += 1\n",
    "print '\\n'\"Best CV score: {}\".format(max(scores))\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(range(2,11),scores)\n",
    "    plt.xlabel('K-fold')\n",
    "    plt.ylabel('Cross-val score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33377967669417036"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the CV score for 5-fold cross-validation\n",
    "cv_score_5fold = cross_val_score(model_lr,X,y,cv=5).mean()\n",
    "cv_score_5fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046147321802189605"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To obtain coefficients of features, we need to do a test train split, fit, predict, score and get coefs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "lr_fitted = model_lr.fit(X_train,y_train)\n",
    "lr_fitted.score(X_test,y_test)\n",
    "(lr_fitted.coef_).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Logistic Regression is doing pretty badly above.**\n",
    "\n",
    "1) I will synthetically upsample (SMOTE) response # 3,4 and downsample response 6,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         274.5972           3.2570            3.51s\n",
      "         2         264.3534           5.6166            3.95s\n",
      "         3         252.0618           3.2046            3.93s\n",
      "         4         239.8876           2.8477            3.76s\n",
      "         5         227.2196           2.3699            3.68s\n",
      "         6         217.0328           1.7585            3.50s\n",
      "         7         209.3303           1.7967            3.47s\n",
      "         8         203.6786           2.2674            3.43s\n",
      "         9         197.2608           2.3208            3.38s\n",
      "        10         185.2296           1.6168            3.27s\n",
      "        20         136.7484           0.8035            2.71s\n",
      "        30         104.5300           0.1817            2.40s\n",
      "        40          90.3773          -0.2431            2.04s\n",
      "        50          76.2004          -0.3084            1.67s\n",
      "        60          59.9695          -0.3290            1.31s\n",
      "        70          53.0371          -0.1915            0.98s\n",
      "        80          41.1573          -0.2156            0.65s\n",
      "        90          37.3883          -0.1644            0.33s\n",
      "       100          30.3457          -0.2271            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         280.3641           4.8139            3.25s\n",
      "         2         262.9038           4.1438            3.33s\n",
      "         3         252.0946           3.3632            3.32s\n",
      "         4         242.3652           3.6024            3.18s\n",
      "         5         236.2943           2.8222            3.17s\n",
      "         6         222.8558           1.2661            3.08s\n",
      "         7         215.9512           2.5287            3.15s\n",
      "         8         206.6331           2.3019            3.11s\n",
      "         9         197.7716           2.2344            3.06s\n",
      "        10         195.9870           1.0798            3.00s\n",
      "        20         137.5193          -0.7086            2.58s\n",
      "        30         121.6971          -0.1165            2.27s\n",
      "        40          98.1043          -0.1917            1.96s\n",
      "        50          80.3292          -0.0732            1.67s\n",
      "        60          68.3401          -0.3198            1.32s\n",
      "        70          60.9286          -0.3227            1.00s\n",
      "        80          53.1113          -0.2461            0.67s\n",
      "        90          47.2415          -0.2465            0.33s\n",
      "       100          38.7380          -0.1758            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         345.5888           2.8173            3.33s\n",
      "         2         329.7244           2.9324            3.11s\n",
      "         3         311.7361           3.1113            3.52s\n",
      "         4         297.3453           1.6449            3.43s\n",
      "         5         284.2557           1.3283            3.63s\n",
      "         6         267.4309           0.8322            3.46s\n",
      "         7         257.9518           1.8324            3.52s\n",
      "         8         249.6704           1.7950            3.44s\n",
      "         9         241.6361           1.7199            3.41s\n",
      "        10         224.6445           0.7944            3.40s\n",
      "        20         165.3097           0.3424            3.09s\n",
      "        30         130.9165          -0.0280            2.51s\n",
      "        40         109.0510          -0.0416            2.09s\n",
      "        50          88.6159          -0.1373            1.78s\n",
      "        60          70.7408          -0.1554            1.39s\n",
      "        70          60.2927          -0.1064            1.04s\n",
      "        80          50.4215          -0.2016            0.68s\n",
      "        90          42.9169          -0.1427            0.34s\n",
      "       100          37.3487          -0.1221            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         352.4569           3.5068            3.55s\n",
      "         2         334.3183           2.4968            3.53s\n",
      "         3         316.9959           1.7082            3.40s\n",
      "         4         302.0357           1.4700            3.79s\n",
      "         5         289.4530           1.7944            4.02s\n",
      "         6         276.5157           1.4886            3.82s\n",
      "         7         268.6335           1.1498            3.87s\n",
      "         8         260.8449           0.7885            3.70s\n",
      "         9         247.7593           0.2789            3.63s\n",
      "        10         239.4609           0.3132            3.50s\n",
      "        20         184.9205           0.2211            2.80s\n",
      "        30         143.2930          -0.0776            2.40s\n",
      "        40         114.3536          -0.0585            2.09s\n",
      "        50          94.6752          -0.2997            1.71s\n",
      "        60          85.8896          -0.1669            1.35s\n",
      "        70          67.8819          -0.2102            1.01s\n",
      "        80          58.8370          -0.1655            0.68s\n",
      "        90          51.0477          -0.0584            0.34s\n",
      "       100          43.0970          -0.0284            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         420.9859           2.2928            3.08s\n",
      "         2         394.2899           1.2370            2.99s\n",
      "         3         373.5863           0.8337            3.08s\n",
      "         4         356.8500           0.8388            3.02s\n",
      "         5         339.1571           0.4262            3.30s\n",
      "         6         324.5971           0.0817            3.21s\n",
      "         7         313.8028           0.3249            3.21s\n",
      "         8         301.0827           0.5069            3.22s\n",
      "         9         289.1635           0.2918            3.37s\n",
      "        10         279.7928           0.2458            3.69s\n",
      "        20         206.5939          -0.0140            3.19s\n",
      "        30         158.2509          -0.0159            2.74s\n",
      "        40         123.5696          -0.0298            2.23s\n",
      "        50         100.2506          -0.1014            1.79s\n",
      "        60          86.0077          -0.0849            1.40s\n",
      "        70          70.6177          -0.1581            1.03s\n",
      "        80          62.8227          -0.0419            0.68s\n",
      "        90          52.6406          -0.0683            0.34s\n",
      "       100          45.8894          -0.0248            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         426.1213           1.8632            3.30s\n",
      "         2         404.3891           1.5342            3.26s\n",
      "         3         384.0198           1.2235            3.92s\n",
      "         4         366.4333           0.6552            4.41s\n",
      "         5         347.0119           0.6512            4.21s\n",
      "         6         331.0150           0.3276            3.95s\n",
      "         7         321.4734           0.3279            3.98s\n",
      "         8         310.3184           0.2055            3.95s\n",
      "         9         297.2423           0.2632            3.81s\n",
      "        10         289.7042           0.3951            3.70s\n",
      "        20         211.1327          -0.2396            2.96s\n",
      "        30         167.4100          -0.2626            2.55s\n",
      "        40         141.0574          -0.0915            2.10s\n",
      "        50         118.9233          -0.1563            1.72s\n",
      "        60          98.3526          -0.0932            1.36s\n",
      "        70          83.1933          -0.1346            1.01s\n",
      "        80          69.1316          -0.1136            0.66s\n",
      "        90          58.8241          -0.1169            0.33s\n",
      "       100          49.8779          -0.0539            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         260.3362           5.4592            5.88s\n",
      "         2         238.5859           4.0842            6.06s\n",
      "         3         223.4076           5.0114            6.22s\n",
      "         4         205.2790           4.5677            6.14s\n",
      "         5         191.2857           1.4587            6.06s\n",
      "         6         181.9494           2.5106            6.04s\n",
      "         7         168.0661           1.5950            6.01s\n",
      "         8         157.9621           1.8547            6.00s\n",
      "         9         150.9100           2.1909            6.07s\n",
      "        10         136.4819           1.8600            5.94s\n",
      "        20          81.0695           0.1485            5.05s\n",
      "        30          51.3739           0.2509            4.31s\n",
      "        40          32.3176          -0.0014            3.67s\n",
      "        50          21.9731          -0.0396            3.03s\n",
      "        60          13.1319          -0.0222            2.41s\n",
      "        70           9.4694          -0.0362            1.79s\n",
      "        80           6.4630          -0.0338            1.18s\n",
      "        90           4.6396          -0.0234            0.59s\n",
      "       100           3.1096          -0.0285            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.2344           5.2247            6.42s\n",
      "         2         245.7161           5.6352            6.20s\n",
      "         3         225.3801           3.5705            6.17s\n",
      "         4         208.5687           3.2326            6.17s\n",
      "         5         196.7063           2.6061            6.06s\n",
      "         6         181.2026           2.1224            6.10s\n",
      "         7         169.7710           2.2891            6.20s\n",
      "         8         159.8394           0.8365            6.32s\n",
      "         9         151.8540           2.4624            6.24s\n",
      "        10         147.8990           1.0936            6.21s\n",
      "        20          84.3223           0.6748            5.71s\n",
      "        30          51.1735          -0.0206            4.78s\n",
      "        40          32.2886           0.0231            3.94s\n",
      "        50          20.7434           0.1340            3.23s\n",
      "        60          13.6650           0.0305            2.61s\n",
      "        70           9.7812          -0.0225            1.92s\n",
      "        80           6.5762          -0.0513            1.26s\n",
      "        90           4.6994          -0.0155            0.63s\n",
      "       100           3.1051          -0.0324            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         326.4270           3.5547            5.34s\n",
      "         2         299.9596           2.0521            5.52s\n",
      "         3         273.3644           3.4533            5.57s\n",
      "         4         249.7085           2.2712            6.62s\n",
      "         5         232.1808           1.7901            6.41s\n",
      "         6         216.3213           1.7788            6.93s\n",
      "         7         202.8747           1.7426            6.98s\n",
      "         8         184.8186           0.9512            7.00s\n",
      "         9         175.1120           0.7415            7.06s\n",
      "        10         166.0156           0.9045            6.88s\n",
      "        20          89.0393           0.2207            5.58s\n",
      "        30          52.1896          -0.1055            4.84s\n",
      "        40          29.1392          -0.0716            4.12s\n",
      "        50          18.4095          -0.0091            3.38s\n",
      "        60          10.7510          -0.0246            2.67s\n",
      "        70           6.9760           0.0126            2.03s\n",
      "        80           4.2089          -0.0022            1.35s\n",
      "        90           2.6452           0.0017            0.67s\n",
      "       100           1.7782          -0.0042            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         326.3324           2.8192            8.09s\n",
      "         2         299.7267           3.3793            7.61s\n",
      "         3         274.6985           1.8772            7.01s\n",
      "         4         255.3307           2.8200            6.93s\n",
      "         5         238.1043           0.9359            6.90s\n",
      "         6         217.7395           1.6704            7.25s\n",
      "         7         207.5757           1.6620            7.03s\n",
      "         8         190.2511           1.4668            6.89s\n",
      "         9         179.4403           1.8197            6.76s\n",
      "        10         167.7571           0.9582            6.60s\n",
      "        20          89.6034           0.2676            5.82s\n",
      "        30          53.0755           0.1281            5.40s\n",
      "        40          31.3241           0.0491            4.57s\n",
      "        50          18.5451           0.0423            3.70s\n",
      "        60          11.8977           0.0250            2.91s\n",
      "        70           7.2289          -0.0176            2.14s\n",
      "        80           4.6763          -0.0071            1.42s\n",
      "        90           2.9271          -0.0064            0.70s\n",
      "       100           1.8549          -0.0074            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         398.8006           1.4125            5.79s\n",
      "         2         355.4504           1.1130            7.02s\n",
      "         3         323.6025           0.8008            6.68s\n",
      "         4         292.9349           0.2430            6.64s\n",
      "         5         273.3313           0.8079            6.54s\n",
      "         6         254.0963           0.8581            6.41s\n",
      "         7         234.1970           0.8521            6.30s\n",
      "         8         217.1219           0.2653            6.27s\n",
      "         9         202.7747           0.3666            6.19s\n",
      "        10         189.3212           0.1340            6.05s\n",
      "        20          95.5932           0.0503            5.56s\n",
      "        30          51.3366           0.0124            4.94s\n",
      "        40          28.9084          -0.0029            4.14s\n",
      "        50          15.7167          -0.0080            3.48s\n",
      "        60           8.3657          -0.0074            2.77s\n",
      "        70           4.8215           0.0028            2.09s\n",
      "        80           2.7882          -0.0037            1.40s\n",
      "        90           1.6278          -0.0027            0.69s\n",
      "       100           0.9616          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         398.9397           1.8662            6.20s\n",
      "         2         356.4090           0.2596            6.30s\n",
      "         3         326.9364           0.3333            6.33s\n",
      "         4         301.3993           0.7111            6.74s\n",
      "         5         277.3158           0.3400            6.77s\n",
      "         6         256.9901           0.8346            6.66s\n",
      "         7         237.3543          -0.0334            6.61s\n",
      "         8         221.1840           0.3008            6.53s\n",
      "         9         205.5614           0.5434            6.43s\n",
      "        10         190.9690           0.2577            6.51s\n",
      "        20         100.4696           0.0615            5.64s\n",
      "        30          54.0206          -0.0197            5.02s\n",
      "        40          30.1045           0.0162            4.31s\n",
      "        50          16.1244          -0.0341            3.58s\n",
      "        60           9.4779           0.0039            2.84s\n",
      "        70           5.4288          -0.0047            2.12s\n",
      "        80           3.0975           0.0011            1.40s\n",
      "        90           1.7696           0.0031            0.69s\n",
      "       100           1.0480          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         254.5383           5.8428            6.25s\n",
      "         2         231.4105           4.4142            8.51s\n",
      "         3         213.5982           2.5163            8.93s\n",
      "         4         198.2556           2.8802            9.01s\n",
      "         5         180.3492           3.0237            9.48s\n",
      "         6         168.8217           3.9559            9.57s\n",
      "         7         154.9319           1.7634            9.67s\n",
      "         8         144.2449           2.1371            9.75s\n",
      "         9         135.2338           1.4201            9.79s\n",
      "        10         125.7688           1.8908            9.77s\n",
      "        20          66.8296           0.3581            8.90s\n",
      "        30          38.8435           0.3761            7.90s\n",
      "        40          21.7363           0.0250            6.79s\n",
      "        50          12.5524           0.0318            5.72s\n",
      "        60           7.4005          -0.0110            4.64s\n",
      "        70           4.8241          -0.0037            3.44s\n",
      "        80           2.8506          -0.0065            2.28s\n",
      "        90           1.8277          -0.0152            1.12s\n",
      "       100           1.1027          -0.0040            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         254.9904           5.9498            6.26s\n",
      "         2         234.0221           5.8700            7.45s\n",
      "         3         211.8417           5.1298            8.34s\n",
      "         4         194.4321           3.7695            8.60s\n",
      "         5         179.8442           1.9996            9.07s\n",
      "         6         167.4551           1.8258           10.16s\n",
      "         7         154.5157           2.5049           10.78s\n",
      "         8         146.8417           1.7187           10.63s\n",
      "         9         134.0763           2.0058           10.55s\n",
      "        10         125.7717           1.1110           10.50s\n",
      "        20          69.3946           0.8792            9.41s\n",
      "        30          37.7659           0.1135            8.40s\n",
      "        40          21.3143           0.0532            7.13s\n",
      "        50          13.3865           0.0038            5.85s\n",
      "        60           7.3991          -0.0127            4.66s\n",
      "        70           4.8385          -0.0213            3.49s\n",
      "        80           2.7223          -0.0149            2.29s\n",
      "        90           1.9180          -0.0279            1.12s\n",
      "       100           1.0737          -0.0174            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         316.6553           4.5822           10.04s\n",
      "         2         284.6156           3.7837           11.08s\n",
      "         3         254.7938           1.8861           10.74s\n",
      "         4         230.9725           1.5229           10.76s\n",
      "         5         211.1512           1.6161           10.70s\n",
      "         6         193.2313           1.5337           10.81s\n",
      "         7         177.5766           1.4017           11.00s\n",
      "         8         163.3978           1.4586           10.97s\n",
      "         9         151.6813           0.9798           10.95s\n",
      "        10         139.3272           0.7455           10.99s\n",
      "        20          65.7718           0.2348           10.19s\n",
      "        30          32.8317           0.0971            9.67s\n",
      "        40          16.7381           0.0062            8.27s\n",
      "        50           8.7974           0.0086            7.13s\n",
      "        60           4.6921           0.0040            5.54s\n",
      "        70           2.4688           0.0032            4.13s\n",
      "        80           1.2643          -0.0012            2.68s\n",
      "        90           0.6828          -0.0020            1.28s\n",
      "       100           0.3718          -0.0011            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         320.4411           5.4805            7.90s\n",
      "         2         285.0623           3.8387            9.17s\n",
      "         3         256.1942           2.4891            9.37s\n",
      "         4         234.5591           2.8015            9.75s\n",
      "         5         211.3895           1.5350            9.76s\n",
      "         6         192.7630           1.0069            9.99s\n",
      "         7         178.1100           1.7615           10.13s\n",
      "         8         166.0040           1.2184           10.13s\n",
      "         9         150.5064           0.9538           10.16s\n",
      "        10         139.2426           0.3286           10.18s\n",
      "        20          66.9112           0.3905            9.65s\n",
      "        30          33.2850           0.1147            8.55s\n",
      "        40          17.1475           0.0181            7.43s\n",
      "        50           9.0432           0.0068            6.43s\n",
      "        60           4.6452           0.0100            5.17s\n",
      "        70           2.4421           0.0003            3.77s\n",
      "        80           1.2649          -0.0024            2.43s\n",
      "        90           0.6997          -0.0015            1.17s\n",
      "       100           0.3618          -0.0023            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         382.2062           2.6317            8.42s\n",
      "         2         334.7314           0.4900            9.37s\n",
      "         3         297.6974           0.6321           10.23s\n",
      "         4         267.4230           1.1308           10.27s\n",
      "         5         240.3731           0.9119           10.46s\n",
      "         6         216.5891           0.2012           10.33s\n",
      "         7         196.7028           1.1688           10.31s\n",
      "         8         178.9079           0.7503           10.28s\n",
      "         9         163.9364           0.5048           10.42s\n",
      "        10         148.4387           0.5273           10.55s\n",
      "        20          63.9701           0.0949           10.52s\n",
      "        30          28.1014           0.0679            9.28s\n",
      "        40          12.6757           0.0111            8.10s\n",
      "        50           5.6938           0.0154            6.58s\n",
      "        60           2.5548           0.0041            5.10s\n",
      "        70           1.1625           0.0030            3.61s\n",
      "        80           0.5230           0.0006            2.30s\n",
      "        90           0.2688           0.0001            1.08s\n",
      "       100           0.1791           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         383.1127           1.4732            9.17s\n",
      "         2         337.1683           1.4099            9.53s\n",
      "         3         299.6552           0.2777            9.41s\n",
      "         4         268.3676           1.0257           10.12s\n",
      "         5         241.5646           0.6330           10.50s\n",
      "         6         219.0817           0.8835           10.74s\n",
      "         7         198.2935           0.5259           10.76s\n",
      "         8         180.6935           0.4288           10.92s\n",
      "         9         164.7241           0.2450           11.01s\n",
      "        10         151.1368           0.1923           10.98s\n",
      "        20          64.4915           0.0833           10.15s\n",
      "        30          29.1331           0.0684            9.22s\n",
      "        40          13.0187           0.0393            8.06s\n",
      "        50           5.8579           0.0115            6.86s\n",
      "        60           2.7434           0.0050            5.33s\n",
      "        70           1.2437           0.0003            3.79s\n",
      "        80           0.5705           0.0002            2.38s\n",
      "        90           0.2917          -0.0001            1.12s\n",
      "       100           0.1834           0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         253.0045          10.6295            3.19s\n",
      "         2         232.0155           2.1938            3.07s\n",
      "         3         214.2123           5.2596            3.12s\n",
      "         4         197.0272           3.0056            3.04s\n",
      "         5         178.0838           2.2516            3.03s\n",
      "         6         172.4988           2.9306            3.01s\n",
      "         7         165.2742           2.3221            2.94s\n",
      "         8         154.0237           0.5912            2.93s\n",
      "         9         141.9925           0.3809            2.90s\n",
      "        10         139.0700           0.8289            2.85s\n",
      "        20          84.2639          -0.6126            2.49s\n",
      "        30          59.0790          -0.5289            2.16s\n",
      "        40          41.6283          -0.3502            1.83s\n",
      "        50          33.2701          -0.2651            1.52s\n",
      "        60          26.6619          -0.2544            1.27s\n",
      "        70          18.7560          -0.2296            0.97s\n",
      "        80          16.2295          -0.1609            0.65s\n",
      "        90          12.6194          -0.1911            0.32s\n",
      "       100          10.3822          -0.1413            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.7404           8.7611            2.90s\n",
      "         2         238.8800           4.1860            3.71s\n",
      "         3         218.5494           3.7532            3.73s\n",
      "         4         199.3759           2.6704            3.54s\n",
      "         5         188.5222           2.7740            3.51s\n",
      "         6         171.3042           2.3270            3.39s\n",
      "         7         166.1258           1.6063            3.43s\n",
      "         8         158.4622           0.8201            3.39s\n",
      "         9         153.3467           0.6428            3.43s\n",
      "        10         139.6990           0.9766            3.46s\n",
      "        20          89.0593          -0.4800            2.81s\n",
      "        30          62.3461          -0.8891            2.37s\n",
      "        40          45.9597          -0.3230            1.98s\n",
      "        50          35.1694          -0.4212            1.65s\n",
      "        60          28.2738          -0.3536            1.34s\n",
      "        70          21.2819          -0.2019            1.00s\n",
      "        80          15.9281          -0.2651            0.67s\n",
      "        90          12.5354          -0.2175            0.33s\n",
      "       100          10.2321          -0.0748            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         316.4130           5.7907           12.20s\n",
      "         2         290.6250           5.2453           11.43s\n",
      "         3         267.2835           3.1237           10.45s\n",
      "         4         249.7172           2.4202            9.26s\n",
      "         5         224.6949           0.3868            8.48s\n",
      "         6         212.7657           1.5682            7.64s\n",
      "         7         197.8118           1.3774            6.90s\n",
      "         8         191.4012           1.3184            6.34s\n",
      "         9         175.7883           0.8992            5.93s\n",
      "        10         168.8127           0.2765            5.64s\n",
      "        20         102.4386          -0.3941            4.30s\n",
      "        30          71.2170          -0.0069            3.57s\n",
      "        40          50.6709          -0.2912            2.87s\n",
      "        50          39.8659          -0.1425            2.27s\n",
      "        60          27.6519          -0.1703            1.81s\n",
      "        70          23.7205          -0.1130            1.37s\n",
      "        80          16.9630          -0.1296            0.91s\n",
      "        90          14.9456          -0.1276            0.47s\n",
      "       100          10.6735          -0.1044            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         323.7014           4.5810            5.37s\n",
      "         2         299.1386           2.9299            4.93s\n",
      "         3         274.4032           3.1507            5.82s\n",
      "         4         245.0859           0.8437            6.03s\n",
      "         5         232.1139           1.4603            5.70s\n",
      "         6         223.7483           1.3493            5.36s\n",
      "         7         204.6420           1.9904            5.13s\n",
      "         8         192.4344           0.9779            4.85s\n",
      "         9         182.4851          -0.2274            4.81s\n",
      "        10         183.0860           0.2869            4.63s\n",
      "        20         113.0324          -0.6801            3.59s\n",
      "        30          77.8377          -0.4995            2.94s\n",
      "        40          56.4932          -0.3181            2.40s\n",
      "        50          41.8172          -0.2199            1.93s\n",
      "        60          31.5737          -0.2008            1.50s\n",
      "        70          23.7104          -0.0422            1.11s\n",
      "        80          19.1682          -0.1035            0.73s\n",
      "        90          15.4869          -0.1267            0.36s\n",
      "       100          11.6441          -0.1144            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         391.6757           2.1494            3.01s\n",
      "         2         348.0284          -0.0844            3.98s\n",
      "         3         320.4852           1.1594            3.58s\n",
      "         4         298.3949           0.9741            3.48s\n",
      "         5         279.2180           1.2074            3.38s\n",
      "         6         262.4600           0.7690            3.90s\n",
      "         7         242.5144           0.2512            3.97s\n",
      "         8         230.6065           0.3511            3.80s\n",
      "         9         218.6719           0.6784            3.81s\n",
      "        10         202.9985          -0.1029            3.71s\n",
      "        20         121.9659          -0.0005            3.09s\n",
      "        30          82.6195          -0.1537            2.55s\n",
      "        40          59.4338          -0.1578            2.16s\n",
      "        50          45.9612          -0.0896            1.76s\n",
      "        60          33.8616          -0.0318            1.44s\n",
      "        70          25.7796          -0.0841            1.07s\n",
      "        80          20.4789          -0.0548            0.70s\n",
      "        90          15.7478          -0.0261            0.34s\n",
      "       100          12.6619          -0.0409            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         396.2905           3.5206            6.04s\n",
      "         2         360.8104           3.2549            4.83s\n",
      "         3         325.0584           0.5014            4.14s\n",
      "         4         303.1386          -0.0257            3.85s\n",
      "         5         283.2888           0.5446            3.72s\n",
      "         6         261.5788          -0.2102            3.62s\n",
      "         7         250.2447           0.8494            3.53s\n",
      "         8         232.0205           0.2869            3.46s\n",
      "         9         220.0913          -0.1343            3.37s\n",
      "        10         203.4538          -0.4965            3.30s\n",
      "        20         133.6081          -0.1355            2.73s\n",
      "        30          95.3696          -0.0893            2.35s\n",
      "        40          65.4924          -0.2126            2.00s\n",
      "        50          50.4928          -0.0690            1.69s\n",
      "        60          37.7566          -0.0246            1.35s\n",
      "        70          29.4219          -0.0736            1.03s\n",
      "        80          21.7337          -0.1128            0.68s\n",
      "        90          17.4762          -0.0384            0.34s\n",
      "       100          13.2598          -0.0262            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.8002           4.0185            4.72s\n",
      "         2         194.4661          10.2574            6.13s\n",
      "         3         166.9410           3.5524            5.87s\n",
      "         4         152.7543           3.4722            5.95s\n",
      "         5         127.8444           1.7907            5.84s\n",
      "         6         120.9955           2.1240            5.82s\n",
      "         7         109.0435           1.3954            5.67s\n",
      "         8          94.9829           1.3338            5.71s\n",
      "         9          85.4790           1.6361            5.64s\n",
      "        10          80.0099           0.5329            5.65s\n",
      "        20          29.2134          -0.1668            4.95s\n",
      "        30          14.0385          -0.0667            4.24s\n",
      "        40           6.7353          -0.0918            3.62s\n",
      "        50           3.0548           0.0229            2.97s\n",
      "        60           1.5188          -0.0135            2.35s\n",
      "        70           0.7042          -0.0178            1.72s\n",
      "        80           0.3563          -0.0034            1.11s\n",
      "        90           0.1965          -0.0041            0.54s\n",
      "       100           0.1200          -0.0015            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         224.7372           5.5874            5.04s\n",
      "         2         192.3307           4.9627            5.51s\n",
      "         3         167.5898           5.2935            5.57s\n",
      "         4         151.1928           3.3196            5.95s\n",
      "         5         131.8705           2.0836            6.13s\n",
      "         6         114.9998           2.2190            5.95s\n",
      "         7         109.0641           2.7325            5.80s\n",
      "         8          94.0262           0.4015            5.95s\n",
      "         9          87.2609           0.9318            5.97s\n",
      "        10          77.3251          -0.2848            5.83s\n",
      "        20          33.8616          -0.0019            4.95s\n",
      "        30          15.0080          -0.2325            4.28s\n",
      "        40           6.5636          -0.0619            3.67s\n",
      "        50           3.2493          -0.0645            3.04s\n",
      "        60           1.8367          -0.0183            2.37s\n",
      "        70           0.9031          -0.0122            1.76s\n",
      "        80           0.4315          -0.0114            1.15s\n",
      "        90           0.2409          -0.0040            0.56s\n",
      "       100           0.1209          -0.0029            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         280.9883          10.0612            5.32s\n",
      "         2         240.2266           4.0578            6.26s\n",
      "         3         208.8841           3.7625            6.91s\n",
      "         4         179.5343           2.8490            6.53s\n",
      "         5         154.3068           1.7061            6.69s\n",
      "         6         134.7751           1.9271            6.97s\n",
      "         7         119.5362           1.7932            6.81s\n",
      "         8         103.9020           0.6400            6.86s\n",
      "         9          94.2376           0.7080            6.83s\n",
      "        10          82.3129           0.6973            6.96s\n",
      "        20          29.0559          -0.0594            5.57s\n",
      "        30          11.0354           0.0019            4.71s\n",
      "        40           4.3975          -0.0132            3.92s\n",
      "        50           1.8705          -0.0152            3.16s\n",
      "        60           0.7771          -0.0063            2.45s\n",
      "        70           0.3682          -0.0033            1.77s\n",
      "        80           0.1902          -0.0013            1.14s\n",
      "        90           0.1222          -0.0007            0.54s\n",
      "       100           0.0989          -0.0004            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         286.8209           5.1472           10.26s\n",
      "         2         240.0746           5.1779            8.48s\n",
      "         3         206.1569           3.0768            7.70s\n",
      "         4         176.8527           2.8764            7.33s\n",
      "         5         159.2555           1.8493            7.05s\n",
      "         6         137.7887           1.3734            6.80s\n",
      "         7         123.6569           1.3258            6.64s\n",
      "         8         110.3756           0.4741            6.53s\n",
      "         9          99.0142           0.8522            6.84s\n",
      "        10          89.7668           0.1985            6.65s\n",
      "        20          30.1644          -0.0802            5.70s\n",
      "        30          11.6212          -0.0313            4.81s\n",
      "        40           4.3277          -0.0412            4.00s\n",
      "        50           1.7730          -0.0026            3.24s\n",
      "        60           0.7816          -0.0010            2.56s\n",
      "        70           0.3293          -0.0018            1.86s\n",
      "        80           0.1647          -0.0019            1.18s\n",
      "        90           0.1126          -0.0002            0.56s\n",
      "       100           0.1038          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         349.3536           3.4285            5.83s\n",
      "         2         287.7055           3.3166            7.56s\n",
      "         3         240.0859           0.5201            7.60s\n",
      "         4         200.9887           0.2385            7.24s\n",
      "         5         177.3534           0.7887            6.93s\n",
      "         6         155.0855           0.3911            6.75s\n",
      "         7         134.4944           0.2686            6.62s\n",
      "         8         117.4282           0.5979            6.50s\n",
      "         9         103.8813           0.3743            6.38s\n",
      "        10          92.2823           0.1001            6.24s\n",
      "        20          26.7349           0.0033            5.38s\n",
      "        30           8.5019           0.0070            4.84s\n",
      "        40           2.8074           0.0023            4.05s\n",
      "        50           1.0298          -0.0011            3.29s\n",
      "        60           0.4101          -0.0012            2.53s\n",
      "        70           0.1825          -0.0008            1.86s\n",
      "        80           0.1282          -0.0002            1.15s\n",
      "        90           0.1165          -0.0001            0.54s\n",
      "       100           0.1116          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         345.0005           5.4380            5.68s\n",
      "         2         285.1617           3.2857            6.00s\n",
      "         3         244.9061           1.7513            6.01s\n",
      "         4         211.6091           1.4018            6.00s\n",
      "         5         180.3482           1.3678            6.07s\n",
      "         6         157.2813           0.4980            6.09s\n",
      "         7         138.7198           0.0865            6.01s\n",
      "         8         122.6068           0.2220            5.95s\n",
      "         9         108.0660           0.4293            5.91s\n",
      "        10          94.8521           0.2329            5.85s\n",
      "        20          27.7968           0.0882            5.20s\n",
      "        30           9.2118          -0.0011            4.92s\n",
      "        40           3.1328           0.0038            4.18s\n",
      "        50           1.0504           0.0023            3.36s\n",
      "        60           0.4006          -0.0016            2.60s\n",
      "        70           0.1884          -0.0004            1.86s\n",
      "        80           0.1318          -0.0001            1.16s\n",
      "        90           0.1195          -0.0001            0.53s\n",
      "       100           0.1213          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         212.1457          12.4593            6.49s\n",
      "         2         181.2098           9.0683            7.61s\n",
      "         3         152.5133           2.0764            8.18s\n",
      "         4         132.4904           3.1594            9.05s\n",
      "         5         116.5321           0.7211           10.32s\n",
      "         6         101.1610           1.7897           10.57s\n",
      "         7          91.4970           0.9454           10.78s\n",
      "         8          82.1287           2.1179           11.13s\n",
      "         9          70.2057           0.4820           11.01s\n",
      "        10          63.6063           1.3227           10.76s\n",
      "        20          21.2847           0.1423            9.15s\n",
      "        30           7.7202          -0.0233            7.91s\n",
      "        40           2.7163          -0.0570            6.53s\n",
      "        50           1.0409          -0.0433            5.19s\n",
      "        60           0.3948          -0.0278            3.90s\n",
      "        70           0.2398          -0.0036            2.75s\n",
      "        80           0.1235          -0.0009            1.70s\n",
      "        90           0.1018          -0.0006            0.79s\n",
      "       100           0.0784          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         213.4074          16.3726            6.29s\n",
      "         2         177.9674           5.5640            7.51s\n",
      "         3         151.8707           6.1462            8.42s\n",
      "         4         133.3540           2.0876            8.70s\n",
      "         5         117.3233           2.2623            8.92s\n",
      "         6         102.4978           2.5492            9.38s\n",
      "         7          90.4278           1.1378            9.28s\n",
      "         8          80.4389           0.9781            9.61s\n",
      "         9          70.3339           0.7773            9.82s\n",
      "        10          61.4654           0.7319            9.98s\n",
      "        20          22.7066           0.0795            9.12s\n",
      "        30           7.3320          -0.0354            7.90s\n",
      "        40           3.2999          -0.0464            6.58s\n",
      "        50           1.2347          -0.0131            5.27s\n",
      "        60           0.6751          -0.0040            4.03s\n",
      "        70           0.2342          -0.0007            2.85s\n",
      "        80           0.1233          -0.0001            1.77s\n",
      "        90           0.1076          -0.0005            0.83s\n",
      "       100           0.0831          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.6481           8.3284            8.12s\n",
      "         2         217.1162           4.1752            8.93s\n",
      "         3         180.8491           4.2774            9.43s\n",
      "         4         154.3540           1.0732            9.84s\n",
      "         5         130.8437           0.6634           10.03s\n",
      "         6         111.7695           1.6385           10.19s\n",
      "         7          96.8629           1.3273           10.17s\n",
      "         8          83.0283           0.7277           10.54s\n",
      "         9          73.3201           1.0617           10.56s\n",
      "        10          62.1412           0.9481           10.52s\n",
      "        20          16.0034           0.1526            9.81s\n",
      "        30           4.1043           0.0209            8.54s\n",
      "        40           1.1342           0.0003            6.97s\n",
      "        50           0.3409          -0.0023            5.36s\n",
      "        60           0.1460           0.0000            3.92s\n",
      "        70           0.1206          -0.0001            2.63s\n",
      "        80           0.1121          -0.0005            1.58s\n",
      "        90           0.1103          -0.0001            0.72s\n",
      "       100           0.1127          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         267.1525           4.9300            7.58s\n",
      "         2         220.5814           2.7433           10.49s\n",
      "         3         184.2816           2.1868           11.76s\n",
      "         4         157.9883           3.0048           11.59s\n",
      "         5         131.3642           1.2048           11.41s\n",
      "         6         113.2938           1.8374           11.24s\n",
      "         7          95.6730           1.1684           11.50s\n",
      "         8          84.0823           1.2090           11.32s\n",
      "         9          73.6041           0.8915           11.12s\n",
      "        10          63.5809           0.5091           11.16s\n",
      "        20          17.1168           0.0578            9.86s\n",
      "        30           4.6454           0.0208            8.51s\n",
      "        40           1.4698           0.0022            7.00s\n",
      "        50           0.4094          -0.0088            5.47s\n",
      "        60           0.1717          -0.0006            4.01s\n",
      "        70           0.1255          -0.0001            2.73s\n",
      "        80           0.1059          -0.0006            1.65s\n",
      "        90           0.1108           0.0001            0.75s\n",
      "       100           0.1040          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         318.4902           2.9065           10.99s\n",
      "         2         253.5764           2.1101           10.98s\n",
      "         3         207.1214           0.9308           10.93s\n",
      "         4         170.8331           0.1115           10.70s\n",
      "         5         142.5132           1.3856           10.86s\n",
      "         6         120.2060           0.5928           10.97s\n",
      "         7         100.6328           0.5210           11.43s\n",
      "         8          84.9505           0.3659           11.68s\n",
      "         9          71.9186           0.4558           11.52s\n",
      "        10          60.2016           0.2870           11.45s\n",
      "        20          12.0392           0.0348           10.83s\n",
      "        30           2.5682           0.0061            8.99s\n",
      "        40           0.5225           0.0016            6.91s\n",
      "        50           0.1819           0.0003            5.09s\n",
      "        60           0.1471           0.0001            3.55s\n",
      "        70           0.1421           0.0000            2.35s\n",
      "        80           0.1390           0.0000            1.41s\n",
      "        90           0.1363          -0.0000            0.65s\n",
      "       100           0.1352          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         321.4757           3.0589            8.58s\n",
      "         2         254.8970           2.8709            9.70s\n",
      "         3         207.3900           1.4927           10.16s\n",
      "         4         171.2011           1.7948           10.46s\n",
      "         5         142.0574           0.4901           10.53s\n",
      "         6         119.1965           0.8784           10.62s\n",
      "         7          99.7162           0.5879           10.66s\n",
      "         8          84.9525           0.2396           10.59s\n",
      "         9          71.3775           0.4011           10.54s\n",
      "        10          61.1403           0.0842           10.83s\n",
      "        20          12.3956           0.0620            9.74s\n",
      "        30           2.5688           0.0029            8.33s\n",
      "        40           0.5481          -0.0005            6.54s\n",
      "        50           0.1785          -0.0000            4.92s\n",
      "        60           0.1464           0.0000            3.46s\n",
      "        70           0.1363          -0.0000            2.31s\n",
      "        80           0.1349           0.0000            1.40s\n",
      "        90           0.1313          -0.0001            0.64s\n",
      "       100           0.1358          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         132.9608          21.6779            3.04s\n",
      "         2         107.3449         -74.1805            4.45s\n",
      "         3          78.3951        -110.3858            3.88s\n",
      "         4         151.4858       -2513.2612            4.33s\n",
      "         5        2568.8360      -67770.6590            3.98s\n",
      "         6        1740.9412         -24.7375            4.19s\n",
      "         7       70314.4316          -3.7697            3.99s\n",
      "         8       35621.3730          -3.4084            4.10s\n",
      "         9       70371.1856          -1.9318            3.89s\n",
      "        10         929.3985          -1.7161            4.00s\n",
      "        20       70348.0623          -0.8344            2.92s\n",
      "        30       36386.9821          -0.2886            2.44s\n",
      "        40       70326.7347          -0.0924            2.01s\n",
      "        50       70198.0909           0.1867            1.64s\n",
      "        60        1684.5515           0.0577            1.29s\n",
      "        70       34736.0603          -0.9177            0.96s\n",
      "        80       35553.6154           0.2899            0.64s\n",
      "        90       69386.7440          -0.0224            0.31s\n",
      "       100       36323.2305          -0.9437            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         155.7406           9.0492            2.93s\n",
      "         2         122.0380         -53.8131            2.94s\n",
      "         3         103.0623         -31.6037            3.03s\n",
      "         4          80.9425       -2261.8544            2.96s\n",
      "         5        2305.3239    -1057848.6034            2.96s\n",
      "         6        2283.9825       -4854.6336            2.90s\n",
      "         7        4866.0675         -19.9704            2.89s\n",
      "         8     1060080.8427      -43328.0663            2.83s\n",
      "         9     1081722.8162          -6.1971            2.82s\n",
      "        10     1064888.7157          -2.7462            2.80s\n",
      "        20       28711.9867          -0.8983            2.38s\n",
      "        30     1103344.3131           0.0944            2.04s\n",
      "        40       50356.0764          -0.1360            1.76s\n",
      "        50     1101109.2571           0.0419            1.45s\n",
      "        60       21657.2201           0.2673            1.15s\n",
      "        70     1105917.1720           0.1210            0.85s\n",
      "        80     1079446.2985           0.3694            0.57s\n",
      "        90     1084252.7481          -0.8809            0.29s\n",
      "       100     1064817.2077          -0.9471            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         197.1602          10.9261            2.86s\n",
      "         2         149.8682          -9.1160            2.82s\n",
      "         3         108.4357         -71.8506            3.17s\n",
      "         4         136.4234 -586275336429.5786            3.15s\n",
      "         5 586275336542.6716           0.0414            3.09s\n",
      "         6 293137668328.1138          -4.1987            3.00s\n",
      "         7 586275336515.3107         -36.4267            2.96s\n",
      "         8 293137668272.0379          -0.7853            2.90s\n",
      "         9 293137668256.2932         -34.3523            2.90s\n",
      "        10 293137667966.0394          -0.1984            2.86s\n",
      "        20 586275336184.2395          -0.4721            2.47s\n",
      "        30          47.5875           0.5648            2.21s\n",
      "        40          45.3695          -0.0211            1.85s\n",
      "        50 586275336129.9249          -0.0591            1.53s\n",
      "        60 586275336172.8615          -0.0038            1.21s\n",
      "        70           0.2057          -0.0739            0.89s\n",
      "        80 586275336172.5714          -0.0019            0.58s\n",
      "        90 586275336172.9161          -0.0002            0.28s\n",
      "       100 586275336172.6832          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         199.0971           9.8292            3.86s\n",
      "         2         139.4835          -6.9367            4.92s\n",
      "         3         114.1842         -62.2192            4.25s\n",
      "         4          92.7173          -0.6403            3.76s\n",
      "         5          79.5635          -7.5722            3.57s\n",
      "         6          60.8964          -5.5551            3.39s\n",
      "         7          50.9234          -3.7874            3.29s\n",
      "         8          42.5890          -3.0268            3.23s\n",
      "         9          37.4401          -0.3197            3.16s\n",
      "        10          31.8715          -1.1850            3.06s\n",
      "        20           9.4453          -0.3051            2.58s\n",
      "        30           2.9630          -0.1591            2.44s\n",
      "        40           1.1205          -0.0385            1.97s\n",
      "        50           0.4188          -0.0174            1.58s\n",
      "        60           0.1842          -0.0087            1.23s\n",
      "        70           0.1013          -0.0019            0.89s\n",
      "        80           0.0774          -0.0007            0.57s\n",
      "        90           0.0769          -0.0006            0.27s\n",
      "       100           0.0725          -0.0008            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.8758           6.6218            3.26s\n",
      "         2         187.4021         -19.5952            3.43s\n",
      "         3    42767458.7079          -8.0853            3.33s\n",
      "         4    42767430.6065          -2.5783            3.12s\n",
      "         5    42767408.1816          -1.5921            3.09s\n",
      "         6    42767386.1550          -0.6839            3.06s\n",
      "         7          56.8365          -1.0757            3.06s\n",
      "         8    42767365.7921          -0.6863            3.01s\n",
      "         9    42767356.6524          -0.7347            2.98s\n",
      "        10    42767356.4029          -0.5691            2.88s\n",
      "        20    42767328.2596          -0.3069            2.58s\n",
      "        30    42767315.2308          -0.0842            2.23s\n",
      "        40           4.4224          -0.1557            1.90s\n",
      "        50    42767299.8563          -0.0199            1.57s\n",
      "        60    42767293.4441          -0.0195            1.23s\n",
      "        70           0.9419          -0.2113            0.90s\n",
      "        80    42767282.4818          -0.0053            0.59s\n",
      "        90           0.3399          -0.4135            0.29s\n",
      "       100    42767272.4213          -0.0034            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         251.3028           7.4261            3.56s\n",
      "         2         201.2899           2.6486            4.71s\n",
      "         3         149.6836          -4.7028            4.19s\n",
      "         4         123.0893          -1.2620            4.56s\n",
      "         5          96.7693          -0.8653            4.47s\n",
      "         6          70.4655          -1.1679            4.13s\n",
      "         7          60.2240          -0.7715            3.97s\n",
      "         8          53.1783          -1.1303            3.81s\n",
      "         9          46.0927          -0.6036            3.66s\n",
      "        10          38.6618          -0.5258            3.52s\n",
      "        20          10.9794          -0.0366            2.73s\n",
      "        30           3.4219          -0.0417            2.26s\n",
      "        40           1.2749          -0.0270            1.88s\n",
      "        50           0.4603          -0.0064            1.53s\n",
      "        60           0.1940          -0.0010            1.22s\n",
      "        70           0.1043          -0.0011            0.87s\n",
      "        80           0.0958          -0.0000            0.55s\n",
      "        90           0.0958          -0.0001            0.26s\n",
      "       100           0.0975          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          68.9751         -15.8581            5.10s\n",
      "         2          31.4969         -24.9578            5.34s\n",
      "         3          23.2131      -14387.1562            5.27s\n",
      "         4       14396.6061        -112.2295            5.74s\n",
      "         5       14392.1731          -0.1905            5.79s\n",
      "         6           7.7542 -17554085138325.6270            5.63s\n",
      "         7 8777042583624.5205          -1.7236            5.52s\n",
      "         8 8777042569242.7158          -0.8613            5.41s\n",
      "         9 17553545198046.2539          -0.8308            5.53s\n",
      "        10 8777582523906.5947          -0.5283            5.53s\n",
      "        20 8777582523724.6025          -0.3418            4.31s\n",
      "        30 17553545198011.8711           0.2434            3.40s\n",
      "        40 8777582523875.4131          -0.4971            2.67s\n",
      "        50 17554085152643.9883          -0.0004            2.11s\n",
      "        60 8777582538220.4600           0.0693            1.56s\n",
      "        70 17554085152621.3047          -0.0010            1.12s\n",
      "        80 8777042569206.7129           0.0723            0.72s\n",
      "        90 8777042583381.5791           0.4727            0.35s\n",
      "       100 8777582538168.9834          -0.2275            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          66.1151         -14.8363            5.29s\n",
      "         2          32.5879        -156.4098            5.59s\n",
      "         3          26.9688     -410861.8244            6.68s\n",
      "         4      204707.8041        -232.2848            6.23s\n",
      "         5      206141.4601 -5131057774788.6377            6.42s\n",
      "         6     3716632.3640        -530.0430            6.32s\n",
      "         7     3718591.9654          -1.6465            6.43s\n",
      "         8 5131058186201.7217 -1751399855082.7224            6.35s\n",
      "         9 6882458041280.7119          -0.2700            6.13s\n",
      "        10 1751403572230.0200           0.2412            5.91s\n",
      "        20 5131054264869.4971           0.3159            4.45s\n",
      "        30     3718048.1465          -0.5332            3.52s\n",
      "        40 6882454324622.3887           0.2562            2.74s\n",
      "        50 6882454324102.7910          -0.4157            2.11s\n",
      "        60     3718031.6144          -0.0840            1.64s\n",
      "        70 1751400060275.6592          -0.0098            1.18s\n",
      "        80 1751403777791.7178          -0.1309            0.77s\n",
      "        90 1751400060272.0244           0.1436            0.37s\n",
      "       100 1751403776865.0896          -0.2715            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          76.6452          -4.7404            6.63s\n",
      "         2          38.5967         -10.8654            6.88s\n",
      "         3          21.4778         -30.8317            6.70s\n",
      "         4          12.3396           0.7639            6.43s\n",
      "         5           8.3398          -8.9475            6.16s\n",
      "         6           5.3155           0.0627            5.98s\n",
      "         7           3.7251          -0.0668            6.07s\n",
      "         8           2.1518          -0.1724            5.95s\n",
      "         9           1.6036          -0.1321            5.79s\n",
      "        10           1.0845          -0.1281            5.67s\n",
      "        20           0.0970          -0.0023            4.01s\n",
      "        30           0.0733          -0.0003            2.79s\n",
      "        40           0.0701          -0.0005            2.06s\n",
      "        50           0.0746          -0.0005            1.55s\n",
      "        60           0.0720          -0.0005            1.18s\n",
      "        70           0.0695          -0.0007            0.83s\n",
      "        80           0.0707           0.0002            0.53s\n",
      "        90           0.0735          -0.0004            0.25s\n",
      "       100           0.0698          -0.0006            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          82.2847           5.6545            6.05s\n",
      "         2          45.5897         -30.1151            6.17s\n",
      "         3          23.8465          -2.8549            6.02s\n",
      "         4          17.7120          -6.5856            5.92s\n",
      "         5          10.2185          -1.0820            5.91s\n",
      "         6           7.3790          -0.5235            5.78s\n",
      "         7           5.6015          -0.0177            5.67s\n",
      "         8           3.8578          -0.0337            5.59s\n",
      "         9           2.3717          -0.1442            5.62s\n",
      "        10           1.7031          -0.1069            5.52s\n",
      "        20           0.1119          -0.0051            4.19s\n",
      "        30           0.0734          -0.0003            2.93s\n",
      "        40           0.0752          -0.0003            2.14s\n",
      "        50           0.0755          -0.0001            1.59s\n",
      "        60           0.0775          -0.0004            1.20s\n",
      "        70           0.0765          -0.0003            0.85s\n",
      "        80           0.0770          -0.0003            0.54s\n",
      "        90           0.0768          -0.0007            0.26s\n",
      "       100           0.0777          -0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         107.3682           0.7262            5.73s\n",
      "         2          48.0956          -9.6530            7.50s\n",
      "         3          23.5019          -0.5750            7.66s\n",
      "         4          13.1079           0.2890            7.22s\n",
      "         5           7.9909          -0.0463            7.05s\n",
      "         6           5.2631          -0.0548            6.88s\n",
      "         7           2.9948          -0.1344            6.68s\n",
      "         8           2.1676          -0.0502            6.48s\n",
      "         9           1.5710           0.0054            6.26s\n",
      "        10           1.1052          -0.0057            5.99s\n",
      "        20           0.0991          -0.0006            4.09s\n",
      "        30           0.0975          -0.0001            2.78s\n",
      "        40           0.0966          -0.0001            2.03s\n",
      "        50           0.0973          -0.0001            1.55s\n",
      "        60           0.0989          -0.0001            1.14s\n",
      "        70           0.0979          -0.0001            0.80s\n",
      "        80           0.0984          -0.0001            0.51s\n",
      "        90           0.0978          -0.0001            0.24s\n",
      "       100           0.0983          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         109.5015         -18.1825            5.80s\n",
      "         2          50.7796          -3.3320            6.37s\n",
      "         3          25.1646           0.0109            6.48s\n",
      "         4          16.2631           0.0668            6.39s\n",
      "         5           9.7889          -0.2193            6.32s\n",
      "         6           5.9070          -0.4829            6.18s\n",
      "         7           3.8191           0.0695            6.14s\n",
      "         8           2.4320          -0.0652            6.08s\n",
      "         9           1.5485          -0.0272            5.89s\n",
      "        10           1.0368           0.0114            5.72s\n",
      "        20           0.1069           0.0000            3.87s\n",
      "        30           0.1008          -0.0004            2.69s\n",
      "        40           0.0994          -0.0001            1.98s\n",
      "        50           0.0999          -0.0001            1.49s\n",
      "        60           0.0985          -0.0001            1.10s\n",
      "        70           0.0971          -0.0001            0.78s\n",
      "        80           0.0977          -0.0002            0.49s\n",
      "        90           0.1000          -0.0000            0.24s\n",
      "       100           0.0958          -0.0006            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          40.2893         -11.4250            7.86s\n",
      "         2          22.2356        -111.3109            8.88s\n",
      "         3          13.4778    -1341550.5512            9.24s\n",
      "         4       72700.8615          -0.4573            9.31s\n",
      "         5     1267753.2545      -42952.1721            9.84s\n",
      "         6       72704.5290           1.2746            9.76s\n",
      "         7      116713.2552          -0.0859            9.56s\n",
      "         8       75044.1834           1.0896            9.36s\n",
      "         9     1383396.0813          -0.8664            9.09s\n",
      "        10     1341635.2099          -0.1500            8.84s\n",
      "        20      117893.9040           0.1057            5.76s\n",
      "        30     1268878.8993           0.0609            4.12s\n",
      "        40        1155.7525           0.2023            3.00s\n",
      "        50     1383315.8870          -0.0771            2.23s\n",
      "        60     1312795.7792           0.1383            1.63s\n",
      "        70       72688.6327          -0.6898            1.14s\n",
      "        80     1310619.9415          -0.2010            0.73s\n",
      "        90     1310562.2560           0.3881            0.35s\n",
      "       100     1383366.9985           0.0160            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          42.3743         -17.6014            7.48s\n",
      "         2          21.1241        -149.3792            9.51s\n",
      "         3          12.0119      -74906.3485            9.93s\n",
      "         4       73646.8896     -934611.3336            9.82s\n",
      "         5         948.0939           2.1693            9.79s\n",
      "         6     1009372.5494 -113602677355.2971            9.60s\n",
      "         7 113603612052.6353           0.2017            9.43s\n",
      "         8 113603686829.6949          -0.4915            9.55s\n",
      "         9       75722.4215           1.2049            9.30s\n",
      "        10 113603684742.9737           0.8305            9.00s\n",
      "        20 113603686859.4819          -0.0120            6.28s\n",
      "        30 113602752232.6223           0.2417            4.40s\n",
      "        40 113603685616.3976           0.1674            3.24s\n",
      "        50       73738.4872           0.1696            2.48s\n",
      "        60        2140.5212          -0.1190            1.83s\n",
      "        70 113603612234.7169           0.3023            1.29s\n",
      "        80     1007376.9679          -0.5514            0.83s\n",
      "        90     1009448.3988           0.0090            0.40s\n",
      "       100 113602751910.9218           0.0349            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          51.8221          -5.9433           10.08s\n",
      "         2          25.3193         -50.8258           12.56s\n",
      "         3          13.7271    -8802660.5529           13.52s\n",
      "         4     8802560.9628           0.4136           13.77s\n",
      "         5         216.4710          -0.1718           13.18s\n",
      "         6     8802659.8579          -0.3532           12.68s\n",
      "         7     8802551.1547           1.0716           12.11s\n",
      "         8     8802445.4130          -0.1077           11.63s\n",
      "         9     8802549.3287          -0.8553           11.04s\n",
      "        10         212.7950          -0.3688           10.53s\n",
      "        20     8802651.1478          -0.0008            5.96s\n",
      "        30         212.0806          -0.0484            3.95s\n",
      "        40     8802644.0665          -0.0006            2.92s\n",
      "        50         105.2820          -0.0372            2.19s\n",
      "        60     8802530.9886           0.0856            1.63s\n",
      "        70     8802631.6728          -0.0004            1.14s\n",
      "        80     8802628.4723          -0.0005            0.73s\n",
      "        90     8802411.7366           0.1724            0.35s\n",
      "       100     8802619.6908          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          53.0681         -12.2513            9.10s\n",
      "         2          24.9340         -17.0451            9.69s\n",
      "         3          13.3510          -6.8217           11.37s\n",
      "         4           8.3397          -0.1112           12.07s\n",
      "         5           4.2018           0.3045           11.75s\n",
      "         6           2.2951          -0.0448           11.51s\n",
      "         7           1.2554           0.0727           11.16s\n",
      "         8           0.7355          -0.1040           10.81s\n",
      "         9           0.3914          -0.0154           10.32s\n",
      "        10           0.2303          -0.0730            9.76s\n",
      "        20           0.0926          -0.0007            5.42s\n",
      "        30           0.0863          -0.0011            3.57s\n",
      "        40           0.0863          -0.0010            2.55s\n",
      "        50           0.0912          -0.0005            1.90s\n",
      "        60           0.0853          -0.0007            1.40s\n",
      "        70           0.0897          -0.0002            0.99s\n",
      "        80           0.0859          -0.0008            0.63s\n",
      "        90           0.0853          -0.0005            0.30s\n",
      "       100           0.0859          -0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          62.4976           0.5324           10.54s\n",
      "         2          26.7196           0.0912           11.37s\n",
      "         3          12.8784           0.0765           11.95s\n",
      "         4           5.9835           0.1784           12.11s\n",
      "         5           2.7867           0.1565           13.03s\n",
      "         6           1.2128           0.0479           12.84s\n",
      "         7           0.6143           0.0090           12.12s\n",
      "         8           0.2836           0.0059           11.28s\n",
      "         9           0.1804           0.0024           10.70s\n",
      "        10           0.1400           0.0004           10.04s\n",
      "        20           0.1171          -0.0001            5.15s\n",
      "        30           0.1175          -0.0004            3.39s\n",
      "        40           0.1109          -0.0002            2.43s\n",
      "        50           0.1140          -0.0001            1.78s\n",
      "        60           0.1167          -0.0001            1.30s\n",
      "        70           0.1132          -0.0001            0.91s\n",
      "        80           0.1119          -0.0009            0.57s\n",
      "        90           0.1088          -0.0011            0.28s\n",
      "       100           0.1158          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          63.7300           4.7370            9.98s\n",
      "         2          26.8933           0.1327           12.61s\n",
      "         3          12.7355           0.4744           12.97s\n",
      "         4           5.9178           0.1342           12.62s\n",
      "         5           2.7264           0.0011           12.17s\n",
      "         6           1.2841          -0.0391           11.84s\n",
      "         7           0.6424           0.0092           11.33s\n",
      "         8           0.3223           0.0058           10.60s\n",
      "         9           0.1914           0.0031            9.84s\n",
      "        10           0.1478           0.0008            9.07s\n",
      "        20           0.1178          -0.0001            4.82s\n",
      "        30           0.1154          -0.0002            3.21s\n",
      "        40           0.1172          -0.0001            2.31s\n",
      "        50           0.1114          -0.0015            1.71s\n",
      "        60           0.1123          -0.0016            1.26s\n",
      "        70           0.1154          -0.0003            0.88s\n",
      "        80           0.1157          -0.0001            0.56s\n",
      "        90           0.1112          -0.0003            0.27s\n",
      "       100           0.1130          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         641.5870          10.7397           18.07s\n",
      "         2         576.5254          11.8467           19.98s\n",
      "         3         514.7064           6.3569           21.83s\n",
      "         4         468.1314           4.2998           23.05s\n",
      "         5         423.8436           4.5849           24.13s\n",
      "         6         388.1302           2.9234           24.46s\n",
      "         7         360.3172           3.1806           24.52s\n",
      "         8         329.4348           2.5176           24.99s\n",
      "         9         306.0280           1.5058           25.60s\n",
      "        10         282.2804           2.2969           25.55s\n",
      "        20         135.2977           0.8512           25.02s\n",
      "        30          66.8890           0.2763           21.38s\n",
      "        40          35.3604           0.1033           18.22s\n",
      "        50          18.7403           0.0221           15.18s\n",
      "        60           9.8872           0.0107           12.04s\n",
      "        70           5.5245          -0.0015            8.90s\n",
      "        80           2.8646           0.0021            5.79s\n",
      "        90           1.5864          -0.0005            2.80s\n",
      "       100           0.8796          -0.0009            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0,\n",
       "              verbose=True, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.6, 0.75, 0.9], 'learning_rate': [0.05, 0.1, 0.5], 'max_depth': [3, 7, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "X = df_predictors_selected\n",
    "y = df_response\n",
    "\n",
    "CV_FOLDS = 2\n",
    "\n",
    "# Set up grid search\n",
    "pgrid = {'learning_rate': [0.05, 0.1, 0.5], #'n_estimators': [1, 10, 100, 1000], \n",
    "         'subsample': [0.6, 0.75, 0.9],\n",
    "         'max_depth': [3,7,15]\n",
    "        }\n",
    "\n",
    "clf_grdbst = GradientBoostingClassifier(verbose=True)\n",
    "\n",
    "grid = GridSearchCV(clf_grdbst, param_grid=pgrid, cv = CV_FOLDS)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.442"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
