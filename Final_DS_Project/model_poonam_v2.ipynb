{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and magic here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read input dataset\n",
    "input_csv = './train.csv'\n",
    "df_raw = pd.read_csv(input_csv, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify predictor variables and response variables, and create corresponding DFs\n",
    "response = 'Response'\n",
    "all_predictors = [col for col in df_raw.columns if col not in response]\n",
    "\n",
    "df_predictors = df_raw[all_predictors]\n",
    "df_response = df_raw[response]\n",
    "df_response_with_dummies = pd.get_dummies(df_response, prefix='Response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Describe each feature: Number of uniques, number of nulls, type_of_feature, distribution\n",
    "\n",
    "def get_dummy_features(df, verbose=False, dummy_threshold = 200):\n",
    "    features_for_dummification = []\n",
    "    num_rows = len(df)\n",
    "\n",
    "    for each_feature in df.columns:\n",
    "        num_uniques = len(df[each_feature].unique())\n",
    "        num_nulls = df[each_feature].isnull().sum()\n",
    "        example = df[each_feature].iloc[0]\n",
    "        \n",
    "        # Keep track of dummy features\n",
    "        if isinstance(example, str) or (num_uniques*dummy_threshold<num_rows and isinstance(example, (int, long))): \n",
    "            features_for_dummification.append(each_feature)\n",
    "\n",
    "        if verbose==True:\n",
    "            print '{}: Uniques: {}/{}. Nulls: {}. Type: {}'.format(each_feature, num_uniques, \n",
    "                                                               num_rows, num_nulls, type_of_feature)\n",
    "            \n",
    "            \n",
    "    return features_for_dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn chosen features into dummy variables\n",
    "def create_dummy_features(df_raw, features_for_dummification, verbose=True):\n",
    "    df_expanded = df_raw\n",
    "\n",
    "    for each_feature in features_for_dummification:\n",
    "        if verbose==True:\n",
    "            print \"Expanding variable: {}\".format(each_feature)\n",
    "        df_temp = pd.get_dummies(df_raw[each_feature], prefix=each_feature)\n",
    "        df_expanded = pd.concat([df_expanded, df_temp], axis = 1, join = 'inner')\n",
    "        df_expanded.drop(each_feature,inplace=True, axis=1)\n",
    "        \n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since training data and test data have different distributions for \"dummyizable\" features, it makes sense to\n",
    "# build out dummy features using a combined distribution\n",
    "df_oos_sneak_peek = pd.read_csv('./test.csv', index_col = 0)\n",
    "df_predictors_enhanced = pd.concat([df_predictors, df_oos_sneak_peek], axis = 0, join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79146, 126)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors_enhanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'Family_Hist_1', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', 'InsuredInfo_7', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_3', 'Medical_History_30', 'Medical_History_31', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_4', 'Medical_History_40', 'Medical_History_41', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7']\n"
     ]
    }
   ],
   "source": [
    "features_for_dummification = get_dummy_features(df_predictors)\n",
    "features_already_dummy = ['Medical_Keyword_{}'.format(num) for num in range(1,49)]\n",
    "features_for_dummification = sorted(list(set(features_for_dummification) - set(features_already_dummy)))\n",
    "print features_for_dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding variable: Employment_Info_2\n",
      "Expanding variable: Employment_Info_3\n",
      "Expanding variable: Employment_Info_5\n",
      "Expanding variable: Family_Hist_1\n",
      "Expanding variable: Insurance_History_1\n",
      "Expanding variable: Insurance_History_2\n",
      "Expanding variable: Insurance_History_3\n",
      "Expanding variable: Insurance_History_4\n",
      "Expanding variable: Insurance_History_7\n",
      "Expanding variable: Insurance_History_8\n",
      "Expanding variable: Insurance_History_9\n",
      "Expanding variable: InsuredInfo_1\n",
      "Expanding variable: InsuredInfo_2\n",
      "Expanding variable: InsuredInfo_3\n",
      "Expanding variable: InsuredInfo_4\n",
      "Expanding variable: InsuredInfo_5\n",
      "Expanding variable: InsuredInfo_6\n",
      "Expanding variable: InsuredInfo_7\n",
      "Expanding variable: Medical_History_11\n",
      "Expanding variable: Medical_History_12\n",
      "Expanding variable: Medical_History_13\n",
      "Expanding variable: Medical_History_14\n",
      "Expanding variable: Medical_History_16\n",
      "Expanding variable: Medical_History_17\n",
      "Expanding variable: Medical_History_18\n",
      "Expanding variable: Medical_History_19\n",
      "Expanding variable: Medical_History_20\n",
      "Expanding variable: Medical_History_21\n",
      "Expanding variable: Medical_History_22\n",
      "Expanding variable: Medical_History_23\n",
      "Expanding variable: Medical_History_25\n",
      "Expanding variable: Medical_History_26\n",
      "Expanding variable: Medical_History_27\n",
      "Expanding variable: Medical_History_28\n",
      "Expanding variable: Medical_History_29\n",
      "Expanding variable: Medical_History_3\n",
      "Expanding variable: Medical_History_30\n",
      "Expanding variable: Medical_History_31\n",
      "Expanding variable: Medical_History_33\n",
      "Expanding variable: Medical_History_34\n",
      "Expanding variable: Medical_History_35\n",
      "Expanding variable: Medical_History_36\n",
      "Expanding variable: Medical_History_37\n",
      "Expanding variable: Medical_History_38\n",
      "Expanding variable: Medical_History_39\n",
      "Expanding variable: Medical_History_4\n",
      "Expanding variable: Medical_History_40\n",
      "Expanding variable: Medical_History_41\n",
      "Expanding variable: Medical_History_5\n",
      "Expanding variable: Medical_History_6\n",
      "Expanding variable: Medical_History_7\n",
      "Expanding variable: Medical_History_8\n",
      "Expanding variable: Medical_History_9\n",
      "Expanding variable: Product_Info_1\n",
      "Expanding variable: Product_Info_2\n",
      "Expanding variable: Product_Info_3\n",
      "Expanding variable: Product_Info_5\n",
      "Expanding variable: Product_Info_6\n",
      "Expanding variable: Product_Info_7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59381, 325)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded_enhanced = create_dummy_features(df_predictors_enhanced, features_for_dummification)\n",
    "df_expanded = df_expanded_enhanced.drop(df_oos_sneak_peek.index)\n",
    "df_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Compute pairwise correlations of all predictors\n",
    "# df_predictors = df_expanded\n",
    "# df_predictor_correlations = df_predictors.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Describe pairwise correlations\n",
    "# _corr_threshold = 0.5\n",
    "\n",
    "# for pred in all_predictors:\n",
    "#     df_temp = df_predictor_correlations[pred]\n",
    "#     max_corr = df_temp[[idx for idx in df_temp.index if pred not in idx]].max()\n",
    "#     min_corr = df_temp.min()\n",
    "#     if np.isnan(max_corr)==False:\n",
    "#         if abs(min_corr)>max_corr:\n",
    "#             other_pred = df_temp[df_temp==min_corr].index[0]\n",
    "#             mcorr = min_corr\n",
    "#         else:\n",
    "#             other_pred = df_temp[df_temp==max_corr].index[0]\n",
    "#             mcorr = max_corr\n",
    "#         if abs(mcorr)>_corr_threshold:\n",
    "#             print '** ',\n",
    "#         print 'mcorr({})={:.4f} with {}'.format(pred, mcorr, other_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0\n",
      "\t\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       83308.0629            6.49m\n",
      "         2       78730.3698            6.08m\n",
      "         3       75269.1612            5.86m\n",
      "         4       72532.5473            5.66m\n",
      "         5       70283.5824            5.54m\n",
      "         6       68424.1147            5.41m\n",
      "         7       66848.2461            5.27m\n",
      "         8       65495.6481            5.18m\n",
      "         9       64329.0702            5.05m\n",
      "        10       63332.1491            4.92m\n",
      "        20       57786.0080            3.66m\n",
      "        30       55368.6307            2.43m\n",
      "        40       54045.7772            1.22m\n",
      "        50       53133.4262            0.00s\n",
      "Score: 0.570245150862\n",
      "Fold #1\n",
      "\t\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       83218.5057            6.22m\n",
      "         2       78645.5464            6.05m\n",
      "         3       75178.5098            6.27m\n",
      "         4       72426.1710            6.03m\n",
      "         5       70231.2163            6.11m\n",
      "         6       68351.8007            5.91m\n",
      "         7       66786.6105            5.72m\n",
      "         8       65461.2612            5.55m\n",
      "         9       64255.7637            5.40m\n",
      "        10       63247.9160            5.23m\n",
      "        20       57703.9099            3.99m\n",
      "        30       55311.0786            2.60m\n",
      "        40       53944.1653            1.28m\n",
      "        50       53039.5144            0.00s\n",
      "Score: 0.575233111961\n",
      "Fold #2\n",
      "\t\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       83214.7785            6.05m\n",
      "         2       78631.0112            5.89m\n",
      "         3       75169.7269            5.74m\n",
      "         4       72424.4152            5.60m\n",
      "         5       70218.0949            5.51m\n",
      "         6       68361.3107            5.42m\n",
      "         7       66761.7040            5.30m\n",
      "         8       65401.3734            5.18m\n",
      "         9       64242.6626            5.12m\n",
      "        10       63231.8722            4.99m\n",
      "        20       57666.5697            3.75m\n",
      "        30       55237.1773            2.46m\n",
      "        40       53821.1820            1.23m\n",
      "        50       52907.1945            0.00s\n",
      "Score: 0.568291700242\n",
      "Fold #3\n",
      "\t\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       83491.6920            6.26m\n",
      "         2       78861.7990            6.16m\n",
      "         3       75426.0071            6.12m\n",
      "         4       72654.1940            6.21m\n",
      "         5       70376.5444            6.18m\n",
      "         6       68430.6181            6.04m\n",
      "         7       66865.4109            5.99m\n",
      "         8       65510.6824            5.84m\n",
      "         9       64359.4094            5.65m\n",
      "        10       63386.0613            5.47m\n",
      "        20       57811.7105            3.95m\n",
      "        30       55406.9566            2.60m\n",
      "        40       54074.9493            1.28m\n",
      "        50       53140.9142            0.00s\n",
      "Score: 0.565125907826\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      111086.4842            9.72m\n",
      "         2      104972.4168            9.09m\n",
      "         3      100340.0845            8.63m\n",
      "         4       96666.2727            8.29m\n",
      "         5       93727.3273            8.00m\n",
      "         6       91144.6707            7.82m\n",
      "         7       89081.2498            7.69m\n",
      "         8       87284.7539            7.68m\n",
      "         9       85725.5209            7.64m\n",
      "        10       84414.6473            7.53m\n",
      "        20       77046.2559            5.67m\n",
      "        30       73965.9588            3.75m\n",
      "        40       72182.5513            1.84m\n",
      "        50       71043.6051            0.00s\n",
      "Final model training score: 0.578956231791\n"
     ]
    }
   ],
   "source": [
    "# Create a test harness: train and test sets\n",
    "# Using k-fold cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df_predictors_selected = df_expanded.copy(deep=True)\n",
    "df_response_selected = df_response\n",
    "\n",
    "# Fill NAs with median estimates (not localized approach yet)\n",
    "df_predictors_selected.fillna(df_predictors_selected.median(), inplace=True)\n",
    "df_response_selected.fillna(df_response_selected.median(), inplace=True)\n",
    "\n",
    "CV_FOLDS = 4\n",
    "skf = KFold(df_response.index.max(), n_folds=CV_FOLDS)\n",
    "ctr_fold = 0\n",
    "\n",
    "# Cross-validation\n",
    "for idx_train, idx_test in skf:\n",
    "    print 'Fold #{}\\n\\t'.format(ctr_fold)\n",
    "    \n",
    "    # Build training and test datasets here\n",
    "    trg_x = df_predictors_selected.ix[idx_train, :].dropna(how='all',axis=0)\n",
    "    trg_y = df_response_selected.ix[idx_train].dropna(how='all', axis=0)\n",
    "    tst_x = df_predictors_selected.ix[idx_test, :].dropna(how='all', axis=0)\n",
    "    tst_y = df_response_selected.ix[idx_test].dropna(how='all', axis=0)\n",
    "    \n",
    "    # Insert main model here\n",
    "#     clf = RandomForestClassifier(n_estimators = 1000) # Score: ~0.226\n",
    "#     clf = KNeighborsClassifier(n_neighbors = 5, weights = 'distance', algorithm = 'ball_tree', n_jobs = -1)\n",
    "    clf = GradientBoostingClassifier(n_estimators = 50, verbose=True, random_state=42)\n",
    "    clf.fit(trg_x, trg_y)\n",
    "\n",
    "    score = clf.score(tst_x, tst_y)\n",
    "    \n",
    "    # Check performance: use accuracy metric\n",
    "    print 'Score: {}'.format(score)\n",
    "    \n",
    "    ctr_fold += 1\n",
    "    \n",
    "    \n",
    "# Final model training/test on ALL training data\n",
    "clf.fit(df_predictors_selected, df_response_selected)\n",
    "print 'Final model training score: {}'.format(clf.score(df_predictors_selected, df_response_selected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve\n",
    "\n",
    "The point is to see if we have enough data. We will do this by determining cross-validated training and test scores for different training set sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample a portion of the dataframe to create a smaller dataframe we can work with for now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, ShuffleSplit \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.learning_curve import learning_curve\n",
    "X = df_predictors_selected\n",
    "y = df_response_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0)#.fit(X_train,Y_train)\n",
    "train_sizes,train_scores,test_scores = learning_curve(model,X,y,train_sizes = np.linspace(0.05,0.1,1),cv = None) \n",
    "                                                     \n",
    "                                         #cv=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.datasets import load_digits\n",
    "estimator = LogisticRegression()\n",
    "title = \"Learning curve Logistic Regression\"\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "cv = cross_validation.ShuffleSplit(digits.data.shape[0], n_iter=100,\n",
    "                                   test_size=0.2, random_state=0)\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building:\n",
    "\n",
    "**Make another version of the data where the minority response values are oversampled OR synthetically generated using SMOTE. First use the original dataset and then the altered for each model:[X,y OR X1,y1]**\n",
    "\n",
    "1. Fit independent models using all features:\n",
    "    1.1 Logistic Regression\n",
    "    1.2 Naive Bayes\n",
    "    1.3 K-Nearest Neighbor\n",
    "\n",
    "\n",
    "\n",
    "2. Plot learning curve for any (?) model that gives a decent accuracy to see if we have enough data in hand!!\n",
    "\n",
    "\n",
    "\n",
    "3. Fit ensemble models using all features:\n",
    "    3.1 RandomForest\n",
    "    3.2 Gradient Boosting Classifier\n",
    "    3.3 Voting Classifier (combo of models from Step#1: show that base classifiers are better than a coin toss)\n",
    "    \n",
    " \n",
    "**Other points to think about:**\n",
    "\n",
    "1) K-fold cross-validation can be folded into the model: each run will give a score: we can get the median score.\n",
    "\n",
    "\n",
    "2) Feature selection: We should apply penalty (C which is 1/lambda.. C=0.1 means high penalty. Apply Lasso). Find coefficients and discuss the importance. Look for intuitive explanations. \n",
    "2.1) For Logistic Regression and Naive Bayes, we will get probabilities so besides just looking at the median CV score,w ill it be useful to look at the confusion matrix, find TPR, FPR, plot a ROC curve and determine AUC? Is that of interest to Prudential??\n",
    "\n",
    "\n",
    "3) To simplify the model, if scores aren't awesome, we can even remove features showing multicollinearity by the correlation rule in the book. (Should we be looking at covariance?). Will PCA help in finding out which features are colinear? Because they will be on the same axis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Out of sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read test dataset\n",
    "df_oos_test = pd.read_csv('./test.csv', index_col = 0)\n",
    "df_oos_test_expanded = create_dummy_features(df_oos_test, features_for_dummification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NAs\n",
    "df_oos_test_expanded.fillna(df_oos_test_expanded.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run classifier\n",
    "df_oos_test_predictions = pd.DataFrame(clf.predict(df_oos_test_expanded), columns = ['Response'], index=df_oos_test_expanded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "\n",
    "# Timestamp filename\n",
    "from time import strftime\n",
    "str_timestamp = strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "df_oos_test_predictions.to_csv('./submission_{}.csv'.format(str_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Account for multi-collinearity\n",
    "# Identify predictors with marginal value, ensure all pairwise correlations are below a certain threshold.\n",
    "# Procedure is from \"Applied Predictive Modeling\" by Max Kuhn, pp. 46-47\n",
    "\n",
    "_multicollinearity_threshold = 0.60\n",
    "\n",
    "# # Isolate just the unique pairwise correlations by dropping lower triangle and diagonal elements\n",
    "df_predictor_correlations = df_predictors.corr()\n",
    "df_corr_temp = df_predictor_correlations.where((np.triu(np.ones(df_predictor_correlations.shape)) \n",
    "                                 - np.identity(len(df_predictor_correlations))).astype(bool))\n",
    "\n",
    "# Create subset DF with pairwise correlations > threshold\n",
    "df_temp = df_corr_temp[df_corr_temp.abs()>_multicollinearity_threshold].dropna(how='all',axis=1).dropna(how='all',axis=0)\n",
    "\n",
    "# Create a list of candidate pairs\n",
    "candidate_pairs = {}\n",
    "for pred in df_temp.columns:\n",
    "    max_abs_corr = df_temp[pred].abs().max()\n",
    "    other_pred = df_temp[df_temp[pred].abs()==max_abs_corr].index[0]\n",
    "    candidate_pairs[(pred, other_pred)] = max_abs_corr\n",
    "\n",
    "# Create a sorted list of candidate pairs\n",
    "candidate_pairs_sorted = sorted(candidate_pairs, key = lambda pair: candidate_pairs[pair], reverse=True)\n",
    "\n",
    "# Create a list of predictors that should be dropped because of collinearity\n",
    "collinear_predictors = []\n",
    "\n",
    "# Remove predictors one by one\n",
    "for pair in candidate_pairs_sorted:\n",
    "    pred_1, pred_2 = pair[0], pair[1]\n",
    "    avg_corr_1, avg_corr_2 = df_predictor_correlations[pred_1].mean(), df_predictor_correlations[pred_2].mean()\n",
    "    if avg_corr_1 > avg_corr_2:\n",
    "        pred_to_remove = pred_1\n",
    "        other_pred = pred_2\n",
    "    else:\n",
    "        pred_to_remove = pred_2\n",
    "        other_pred = pred_1\n",
    "    try:\n",
    "        collinear_predictors.append(pred_to_remove)\n",
    "        print 'Should remove {}. Has a correlation of {:.2f} with {}.'.format(pred_to_remove, candidate_pairs[pair], other_pred)\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detect near-zero variance predictors\n",
    "near_zero_variance_predictors = []\n",
    "\n",
    "for predictor in df_predictors.columns:\n",
    "    pred_mode = df_predictors[predictor].mode()[0]\n",
    "    pred_2nd_mode = df_predictors[predictor][df_predictors[predictor]!=pred_mode].mode()[0]\n",
    "    freq_mode = len(df_predictors[predictor][df_predictors[predictor]==pred_mode])\n",
    "    freq_2nd_mode = len(df_predictors[predictor][df_predictors[predictor]==pred_2nd_mode])\n",
    "    num_uniques = len(df_predictors[predictor].unique())\n",
    "    mode_ratio = float(freq_mode)/freq_2nd_mode\n",
    "    uniques_pct = 100*float(num_uniques)/len(df_predictors)\n",
    "    if mode_ratio>20 and uniques_pct<0.05:\n",
    "        print '*** Near-zero variance predictor',\n",
    "        near_zero_variance_predictors.append(predictor)\n",
    "    print '{}: Mode ratio={:.2f}, uniques={:.4f}%'.format(predictor, mode_ratio, uniques_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a subset of predictors by removing collinear and near-zero variance predictors\n",
    "\n",
    "selected_predictors = list(set(all_predictors) - set(collinear_predictors) - set(near_zero_variance_predictors))\n",
    "df_predictors_subset = df_predictors.ix[:,selected_predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine correlations of predictors with response variable\n",
    "df_selected = df_predictors\n",
    "important_predictors_for_response = {}\n",
    "\n",
    "for response_var in df_response.unique():\n",
    "    response_corrs = df_selected.corrwith(df_response_with_dummies['Response_{}'.format(response_var)]).to_dict()\n",
    "    sorted_corrs = sorted(response_corrs, key=lambda prd: abs(response_corrs[prd]), reverse=True)\n",
    "    important_predictors_for_response[response_var] = zip(sorted_corrs, [response_corrs[corr] for corr in sorted_corrs])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
