{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source:\n",
    "Kaggle (ongoing competition): https://www.kaggle.com/c/prudential-life-insurance-assessment\n",
    "\n",
    "# Project goals:\n",
    "\n",
    "**Analyze features collected from individuals applying for life insurance at Prudential to predict response of the company.**\n",
    "\n",
    "Motivation for the problem:\n",
    "\n",
    "Once Prudential collects features from its applicants, it takes a long time to come up with a decision. If we can come up with a model that accurately predicts the decisions they come up with, the company can use this model and swiftly determine its decision.\n",
    "\n",
    "# Notes on dataset:\n",
    "\n",
    "**59381 rows,  127 columns**: 126 features (some of which are dummy variables) and 1 outcome column. The outcome column is called \"Response\". There are 8 nominal values (1,2,3,4,5,6,7,8) in the Response column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages and magic here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "% matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# globals here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read input data set\n",
    "input_csv = \"./train.csv\"\n",
    "\n",
    "df_raw = pd.read_csv(input_csv,index_col=0)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify predictor varibales and response variable and create corresponding dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for null values\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for unique output column\n",
    "df_raw.Response.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look into the employment column\n",
    "emp_info = ['Employment_Info_1','Employment_Info_2','Employment_Info_3','Employment_Info_4','Employment_Info_5',\n",
    "               'Employment_Info_6']\n",
    "df_raw.ix[2:10,emp_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for correlations among the employment_info columns\n",
    "for ii in emp_info:\n",
    "    plt.scatter(df_raw.ix[:,ii],df_raw.ix[:,'Employment_Info_1'])\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for correlations among the employment_info columns\n",
    "for ii in range(0,len(emp_info)):\n",
    "    for jj in range(ii+1,len(emp_info)):\n",
    "        #print \"{} vs {}\".format(emp_info[ii],emp_info[jj])\n",
    "        plt.scatter(df_raw.ix[:,emp_info[ii]],df_raw.ix[:,emp_info[jj]])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To clearly compute nulls and plot distributions for each feature\n",
    "\n",
    "for each_feature in df_raw.columns:\n",
    "    num_uniques = len(df_raw[each_feature].unique())\n",
    "    num_nulls = df_raw[each_feature].isnull().sum()\n",
    "    print \"{}: uniques = {}, nulls = {}\".format(each_feature,num_uniques,num_nulls)\n",
    "    try:\n",
    "        sns.distplot(df_raw[each_feature].dropna(how=any))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df_raw\n",
    "for each_feature in df2.columns:\n",
    "    num_nulls = df2[each_feature].isnull().sum()\n",
    "    print \"nulls in {}: {}\".format(each_feature,num_nulls)\n",
    "    if num_nulls !=0:\n",
    "        df2.drop([rows for rows in df2[each_feature] if rows==\"NaN\"],axis=0,inplace=True)\n",
    "        new_num_nulls = df2[each_feature].isnull().sum()\n",
    "        print \"new nulls in {}: {}\".format(each_feature,new_num_nulls)\n",
    "        \n",
    "#         df_raw.drop\n",
    "#         print \"after dropping nulls, length of {}: {}\".format(each_feature,len(df_raw[each_feature]))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new list that adds\n",
    "string_variables = []\n",
    "for each_feature in range(0,len(df_raw.columns)):\n",
    "    print type(df_raw.iloc[2,each_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df_raw.Product_Info_2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw.Product_Info_2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dummy variables for Product_info2\n",
    "prod_info_2 = pd.get_dummies(df_raw['Product_Info_2'],prefix=\"Product_Info_2\")\n",
    "prod_info_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop Product_Info_2\n",
    "df_raw.drop(['Product_Info_2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_expanded = pd.concat([df_raw,prod_info_2],axis=1,join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define\n",
    "\n",
    "pred_variables = df_expanded.columns[:-1]\n",
    "pred_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_expanded.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = []\n",
    "for ii in df_expanded.columns:\n",
    "    if ii != \"Response\":\n",
    "        predictors.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor_df = df_expanded.ix[:,predictors]\n",
    "corr_df = predictor_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_corr_threshold = 0.5\n",
    "\n",
    "for pred in predictors:\n",
    "    df_temp = corr_df[pred]\n",
    "    max_corr = df_temp[[idx for idx in df_temp.index if idx not in pred not in idx]].max()\n",
    "    min_corr = df_temp.min()\n",
    "    if np.isnan(max_corr)==False:\n",
    "        if abs(min_corr)>max_corr:\n",
    "            other_pred = df_temp[df_temp==min_corr].index[0]\n",
    "            mcorr = min_corr\n",
    "        else:    \n",
    "            other_pred = df_temp[df_temp==max_corr].index[0]\n",
    "            mcorr = max_corr\n",
    "        if abs(mcorr)>_corr_threshold:\n",
    "              print '**',\n",
    "        print 'max_corr({})={:.4f} with {}'.format(pred,mcorr,other_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hedge for multicollinearity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
